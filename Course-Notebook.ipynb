{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p04tD5372zXf"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lucaase/LFP-analysis-HS/blob/main/Course-Notebook.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "wnw2RlnOwS_R"
      },
      "source": [
        "# **Local field potential analysis with open source tools**\n",
        "\n",
        "Welcome to the 2023 House Symposium of the Brain Institute! This short tutorial is designed to be part of the symposium, offering a comprehensive introduction to the intriguing realm of signal processing and oscillation analyses in neuroscience. Our focus will be on leveraging open-source tools to unravel the mysteries encoded in data recorded at the mesoscopic scale – the Local Field Potential (LFP). The LFP serves as a dynamic window into the activity of a small, localized population of neurons proximate to the recording electrode.\n",
        "\n",
        "**Brain Intitute, Federal University of Rio Grande do Norte**\n",
        "\n",
        "**Content creators**: Lucas CS Tavares (lucastavares@neuro.ufrn.br), Rodrigo MM Santiago (rsantiago@neuro.ufrn.br)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HpnzigXzwS_U"
      },
      "source": [
        "___\n",
        "# Tutorial Objectives\n",
        "\n",
        "*Estimated timing of tutorial: 1h15 minutes*\n",
        "\n",
        "In this immersive tutorial, our primary goals are to equip attendees with the skills to dissect and interpret local field potential data through the lens of open-source tools. Throughout the session, participants will gain proficiency in the following key areas:\n",
        "\n",
        "- **Visualizing Raw Signals and Identifying Artifacts**:\n",
        "    - Explore techniques to visualize raw LFP signals effectively.\n",
        "    - Develop strategies for identifying and mitigating artifacts in the data.\n",
        "- **Transforming Signals: Temporal to Frequency Domain**:\n",
        "    - Learn how to transform temporal signals into the frequency domain.\n",
        "    - Understand the significance of frequency domain analysis in extracting meaningful insights.\n",
        "- **Computing Time-Frequency Profiles (Spectrogram)**:\n",
        "    - Learn the process of computing spectrograms to unveil the time-frequency profile of spectral power in LFP data.\n",
        "    - Gain insights into the dynamic changes in neural activity over time.\n",
        "- **Calculating Phase Coherence Between Signals**:\n",
        "    - Dive into the computation of phase coherence, a crucial measure for understanding synchronization between two signals.\n",
        "    - Uncover the interplay of neural activities reflected in phase relationships.\n",
        "- **Computing the Modulation Index Between Signals of Different Frequencies**:\n",
        "    - Explore advanced analyses by calculating modulation indices between signals of distinct frequencies.\n",
        "    - Understand how different frequency components interact and modulate each other.\n",
        "    \n",
        "\n",
        "<br>\n",
        "\n",
        "**Acknowledgements:**\n",
        "- We thank Prof. Adriano Tort. Much of today's tutorials are inspired by his classes.\n",
        "- This notebook's style was inspired by the ones used in [Neuromatch Academy](https://academy.neuromatch.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "9vQ43bs_wS_U"
      },
      "outputs": [],
      "source": [
        "# @title Tutorial slides\n",
        "# @markdown These are the companion slides for the tutorial.\n",
        "from IPython.display import IFrame\n",
        "link_id = \"n25pb\"\n",
        "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "AKCJxi-SwS_V"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "5cD4uWVMwS_W"
      },
      "outputs": [],
      "source": [
        "# @title Import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "u9wk5eVBwS_W"
      },
      "outputs": [],
      "source": [
        "# @title Figure Settings\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').disabled = True\n",
        "\n",
        "import ipywidgets as widgets  # interactive display\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DDuAkXRq8572"
      },
      "outputs": [],
      "source": [
        "# @title Download data\n",
        "\n",
        "!wget https://github.com/lucaase/LFP-analysis-HS/raw/main/LFPprobe.mat\n",
        "!wget https://github.com/lucaase/LFP-analysis-HS/raw/main/LFP_HG_HFO.mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mfUPJnSNwS_X"
      },
      "source": [
        "---\n",
        "# Section 1: Visualizing the signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-CsQRzS6wS_Y"
      },
      "source": [
        "In this section, we will delve into the essential step of visualizing raw Local Field Potential (LFP) signals and developing techniques to identify and mitigate artifacts. Visualization is a critical first step in understanding the characteristics of our data and ensuring its reliability for subsequent analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "vwrZKMDzwS_Y"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "# @markdown Execute this cell to generate some simulated data. The data is a sum of two sine waves with different frequencies and amplitudes, plus some noise\n",
        "\n",
        "# Setting random seed for reproducibility\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Sampling rate\n",
        "fs = 1000\n",
        "# Time vector of 1 second\n",
        "t = np.arange(0, 1, 1/fs)\n",
        "\n",
        "# Generate two sine waves with different frequencies and amplitudes\n",
        "freq1 = 8 # 8 Hz, or 8 cycles per second\n",
        "freq2 = 30\n",
        "amp1 = 2 # The amplitude of the sine wave\n",
        "amp2 = 1\n",
        "\n",
        "# Generate random noise\n",
        "noise = np.random.normal(0, 0.5, len(t)) # mean, SD, length\n",
        "\n",
        "# Generate signal\n",
        "LFP = amp1 * np.sin(2*np.pi*freq1*t) + amp2 * np.sin(2*np.pi*freq2*t) + noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q9RaltTF2zXj"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "# @markdown Execute this cell to visualize the data\n",
        "\n",
        "# Plot the signal\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.title('Synthetic signal')\n",
        "plt.plot(t, LFP, 'royalblue')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude (a.u.)')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([-6, 6])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhgjTdDO2zXj"
      },
      "source": [
        "## Interactive Demo 1: Playing with signal parameters\n",
        "\n",
        "Using an interactive widget, we can visualize how the manually inserted frequencies are present in the signal, how their amplitudes change and the effect of noise in the time series. This, however, is an overly simplistic representation, as the real signals can be decomposed into indefinite (limited by the sampling rate) frequency components.\n",
        "\n",
        "While decoupling signal from noise in this example is as simple as moving a slider, in the real world it is one of the hardest challenges in neuroscience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MKlkxq0q2zXj"
      },
      "outputs": [],
      "source": [
        "# @title Make sure you execute this cell to enable the widget!\n",
        "\n",
        "@widgets.interact(freq1=widgets.IntSlider(8, min=1, max=50),\n",
        "                  freq2=widgets.IntSlider(30, min=1, max=50),\n",
        "                  amp1=widgets.IntSlider(2, min=1, max=4),\n",
        "                  amp2=widgets.IntSlider(1, min=1, max=4),\n",
        "                  noise=widgets.FloatSlider(0.5, min=0, max=1.0))\n",
        "\n",
        "def plot_data_estimate(freq1, freq2, amp1, amp2, noise):\n",
        "  t = np.arange(0, 1, 1/fs)\n",
        "  LFP = amp1 * np.sin(2*np.pi*freq1*t) + amp2 * np.sin(2*np.pi*freq2*t) + np.random.normal(0, noise, len(t))\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.plot(t, LFP, 'royalblue')\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.ylabel('Amplitude (a.u.)')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([-10, 10])\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roBN4RCD2zXj"
      },
      "source": [
        "#### Sampling rate and aliasing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNUDRity2zXj"
      },
      "source": [
        "This section will showcase the effects that different sampling rates can produce on the recorded signal, and how it can lead to aliasing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsFGGTkV2zXk"
      },
      "outputs": [],
      "source": [
        "# Create a 3x1 figure\n",
        "fig, axs = plt.subplots(3, 1, figsize=(8, 10))\n",
        "\n",
        "# Plot the original signal\n",
        "axs[0].plot(t, LFP, 'royalblue')\n",
        "axs[0].set_title('Original signal')\n",
        "axs[0].set_xlabel('Time (s)')\n",
        "axs[0].set_ylabel('Amplitude (a.u.)')\n",
        "\n",
        "# Subsample the signal at 100 Hz (every 10th sample)\n",
        "sub_LFP = LFP[::10]\n",
        "sub_t = t[::10]\n",
        "\n",
        "# Plot the original signal with subsampling points\n",
        "axs[1].plot(t, LFP, 'royalblue')\n",
        "axs[1].plot(sub_t, sub_LFP, 'ko')\n",
        "axs[1].set_title('Original signal with subsampling points')\n",
        "axs[1].set_xlabel('Time (s)')\n",
        "axs[1].set_ylabel('Amplitude (a.u.)')\n",
        "\n",
        "# Plot the subsampled signal\n",
        "axs[2].plot(sub_t, sub_LFP, 'royalblue')\n",
        "axs[2].set_title('Subsampled signal')\n",
        "axs[2].set_xlabel('Time (s)')\n",
        "axs[2].set_ylabel('Amplitude (a.u.)')\n",
        "\n",
        "# Show the figure\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPKfgadB2zXk"
      },
      "source": [
        "**Aliasing** is a phenomenon in signal processing where a high-frequency signal appears as a lower-frequency signal in the sampled data. This mischaracterization occurs when the sampling rate used to capture a signal is insufficient to accurately represent the original analog signal. Aliasing can lead to a misinterpretation of the true frequency content of the signal and introduce artifacts in the reconstructed signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6UUNY1Kn2zXk"
      },
      "outputs": [],
      "source": [
        "# @title An interactive widget with sliders for frequency and subsampling rate\n",
        "@widgets.interact(freq=widgets.IntSlider(2, min=1, max=20),\n",
        "                  subsample_rate=widgets.IntSlider(100, min=2, max=100))\n",
        "\n",
        "def plot_data_estimate(freq, subsample_rate):\n",
        "  # Generate the time vector\n",
        "  t = np.arange(0, 1, 1/fs)\n",
        "\n",
        "  # Generate the original signal\n",
        "  LFP = np.sin(2*np.pi*freq*t)\n",
        "\n",
        "  # Subsample the signal\n",
        "  sub_LFP = LFP[::int(fs/subsample_rate)]\n",
        "  sub_t = t[::int(fs/subsample_rate)]\n",
        "\n",
        "\n",
        "  # Create a 3x1 figure\n",
        "  fig, axs = plt.subplots(3, 1, figsize=(7, 7))\n",
        "\n",
        "  # Plot the original signal\n",
        "  axs[0].plot(t, LFP, 'royalblue')\n",
        "  axs[0].set_title('Original signal')\n",
        "  axs[0].set_xlabel('Time (s)')\n",
        "  axs[0].set_ylabel('Amplitude (a.u.)')\n",
        "\n",
        "  # Plot the original signal with subsampling points\n",
        "  axs[1].plot(t, LFP, 'royalblue')\n",
        "  axs[1].plot(sub_t, sub_LFP, 'ko')\n",
        "  axs[1].set_title('Original signal with subsampling points')\n",
        "  axs[1].set_xlabel('Time (s)')\n",
        "  axs[1].set_ylabel('Amplitude (a.u.)')\n",
        "\n",
        "  # Plot the subsampled signal\n",
        "  axs[2].plot(sub_t, sub_LFP, 'royalblue')\n",
        "  axs[2].set_title('Subsampled signal')\n",
        "  axs[2].set_xlabel('Time (s)')\n",
        "  axs[2].set_ylabel('Amplitude (a.u.)')\n",
        "\n",
        "  # Show the figure\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbtXBHD52zXk"
      },
      "source": [
        "When a continuous analog signal is sampled at a certain rate, it is converted into a discrete signal by capturing its amplitude at regular intervals. The Nyquist-Shannon sampling theorem states that to avoid aliasing, the sampling rate must be at least twice the frequency of the highest component in the signal. This critical frequency is known as the **Nyquist frequency**.\n",
        "\n",
        "#### Mitigation Strategies:\n",
        "\n",
        "To mitigate aliasing, it is crucial to adhere to the Nyquist sampling criterion by choosing an appropriate sampling rate. If the frequency of a signal exceeds half of the sampling rate, a low-pass anti-aliasing filter can be employed before sampling to remove high-frequency components. This ensures that signals are accurately represented in the digital domain and prevents the introduction of misleading oscillations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTqhSI_2zXk"
      },
      "source": [
        "## Signal artifacts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gsAiptr_wS_Y"
      },
      "source": [
        "### Introducing Artifacts and Artifact Corrections\n",
        "\n",
        "In our exploration, we will intentionally introduce some artifacts into our synthetic signal to observe their impact and subsequently apply artifact correction techniques. Artifacts manifest as undesired features in a signal, such as an overall increase in amplitude, non-stationarity*, or the presence of fixed power in spurious frequencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9oqpLTj2zXk"
      },
      "source": [
        "We will start by generating 5 synthetic signals, which will be our \"channels\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K624C3Ic2zXk"
      },
      "outputs": [],
      "source": [
        "from cycler import cycler\n",
        "\n",
        "# Define your custom color cycle\n",
        "colors = ['royalblue', 'seagreen', 'goldenrod', 'violet', 'firebrick']\n",
        "custom_cycler = cycler(color=colors)\n",
        "\n",
        "t = np.arange(0, 10, 1/fs)\n",
        "n_trials = 5\n",
        "# Generate signals in an array\n",
        "signals = np.zeros((n_trials, len(t)))\n",
        "v_shift = 2.5  # vertical shift between signals\n",
        "\n",
        "# Initialize the frequency vector\n",
        "frequencies = np.arange(0.1, 100, 0.1)\n",
        "# Initialize the amplitude vector (for simplicity, we will assume that the amplitudes are the inverse of the frequencies)\n",
        "amplitudes = 1 / frequencies\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  # assign a random amplitude between 1 and 5\n",
        "  amp = amplitudes[np.random.randint(0, len(frequencies))]\n",
        "  # assign a random frequency between 1 and 100\n",
        "  freq = frequencies[np.random.randint(0, len(frequencies))]\n",
        "  # generate signal\n",
        "  signals[i, :] = (amp * np.sin(2*np.pi*freq*t) + amp * np.sin(2*np.pi*freq*t) + np.random.normal(0, 0.5, len(t))) + v_shift * (4 - i)  # add noise and a constant value to separate signals\n",
        "\n",
        "# Plot the signals without overlaying them\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.set_prop_cycle(custom_cycler)\n",
        "plt.title('Synthetic signals')\n",
        "plt.plot(t, signals.T)  # Use the fixed colors for each signal\n",
        "plt.xlabel('Time (s)')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([-2, 12])  # Adjust y-axis limit to accommodate the constant values\n",
        "plt.yticks(np.arange(0, 12, v_shift), labels=[f'Channel {5-i}' for i in range(5)])  # Add yticks related to each channel\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC_qkrDe2zXk"
      },
      "source": [
        "#### Common Types of Artifacts\n",
        "\n",
        "1. **Overall Increase in Amplitude:**\n",
        "   - This artifact is characterized by a global rise in signal amplitude, often obscuring the underlying patterns of interest.\n",
        "   - Most of the time, this happens due to behaviours outside the scope of the analysed phenomena, such as blinking, motor activity, etc.\n",
        "   \n",
        "2. **Non-Stationarity:**\n",
        "   - Non-stationarity refers to variations in the statistical properties of the signal over time. These variations can hinder the accurate analysis of underlying dynamics.\n",
        "\n",
        "3. **Fixed Power in Spurious Frequencies:**\n",
        "   - Artifacts may introduce power at specific frequencies unrelated to the natural frequency content of the signal, leading to misleading interpretations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyfTi6dm2zXl"
      },
      "outputs": [],
      "source": [
        "# Adding artifacts to the data\n",
        "\n",
        "# Increase the amplitude of the third signal from 2.5 s to 4.5 s\n",
        "signals[2, int(2.5*fs):int(4.5*fs)] = signals[2, int(2.5*fs):int(4.5*fs)] + 4\n",
        "\n",
        "# Create a trend (linear increase) in signal 4\n",
        "signals[3, :] = signals[3, :] + np.linspace(0, 10, len(t))\n",
        "\n",
        "# Increase the power of 60Hz in all signals from 5.5 s to 5.9 s\n",
        "signals[:, int(5.5*fs):int(5.9*fs)] += 0.5*np.sin(2*np.pi*60*t[int(5.5*fs):int(5.9*fs)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_72jmBjm2zXl"
      },
      "source": [
        "Visualizing the data after artifact insertions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EUDQi67k2zXl"
      },
      "outputs": [],
      "source": [
        "# @title Visualize the data with artifacts second by second\n",
        "@widgets.interact(t=widgets.IntSlider(0, min=0, max=9))\n",
        "def plot_data_artifacts(t):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  # Define the time range for one second\n",
        "  time_range = np.arange(t, t+1, 1/fs)\n",
        "\n",
        "  # Compute the min and max values within the current time range\n",
        "  min_value = np.min(signals[:, int(t*fs):int((t+1)*fs)])\n",
        "  max_value = np.max(signals[:, int(t*fs):int((t+1)*fs)])\n",
        "\n",
        "  # Plot each signal in the time range\n",
        "  for i in range(signals.shape[0]):\n",
        "    plt.plot(time_range, signals[i, int(t*fs):int((t+1)*fs)], color=colors[i], label=f'Channel {i+1}')\n",
        "\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.xlim([t, t+1])\n",
        "  plt.ylim([min_value-1, max_value+1])\n",
        "  plt.gca().set_yticklabels([])  # Remove yticklabels\n",
        "  plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjWAGWRV2zXl"
      },
      "source": [
        "### Artifact Corrections\n",
        "\n",
        "Several techniques can be employed to mitigate the impact of artifacts and restore the integrity of the signal:\n",
        "\n",
        "#### 1. Notch Filter:\n",
        "   - **Purpose:** Target and eliminate power at specific frequencies, often associated with external interference.\n",
        "   - **Implementation:** Use notch filters to suppress unwanted frequency components.\n",
        "\n",
        "#### 2. Detrending:\n",
        "   - **Purpose:** Remove long-term trends or baseline shifts in the signal.\n",
        "   - **Implementation:** Apply detrending algorithms to eliminate slow-varying components.\n",
        "\n",
        "#### 3. Removing Defective Channels:\n",
        "   - **Purpose:** Address artifacts originating from specific recording channels.\n",
        "   - **Implementation:** Identify and exclude channels with significant artifacts from further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fPEmpCy2zXl"
      },
      "source": [
        "Notch filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGqTPIqd2zXl"
      },
      "outputs": [],
      "source": [
        "# Import the necessary library\n",
        "import scipy.signal as signal\n",
        "\n",
        "# Initialize the filtered signals array\n",
        "filtered_signals = np.zeros(signals.shape)\n",
        "\n",
        "# Applying a notch filter to remove line (60Hz) noise\n",
        "\n",
        "# Define the notch filter function\n",
        "def notch_filter(data, fs, freq, Q=30):\n",
        "    w0 = freq/(fs/2) # Normalized Frequency\n",
        "    b, a = signal.iirnotch(w0, Q) # Q is the quality factor\n",
        "    filtered_data = signal.filtfilt(b, a, data) # Apply the notch filter\n",
        "\n",
        "    return filtered_data\n",
        "\n",
        "# Apply the notch filter to each channel\n",
        "for i in range(signals.shape[0]):\n",
        "    filtered_signals[i, :] = notch_filter(signals[i, :], fs, freq=60) # Freq is the frequency to be removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EjPCUs12zXl"
      },
      "source": [
        "Detrending a signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "meWp3HnQwS_Y"
      },
      "outputs": [],
      "source": [
        "# Apply the detrending function to the 4th channel\n",
        "filtered_signals[3,:] = signal.detrend(signals[3, :]) + v_shift * 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GCDo7u52zXm"
      },
      "source": [
        "Removing a bad channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLA6tlRU2zXm"
      },
      "outputs": [],
      "source": [
        "# Remove the 3rd channel from the filtered signals array\n",
        "filtered_signals = np.delete(filtered_signals, 2, axis=0)\n",
        "# Remove the corresponding color\n",
        "colors.pop(2)  # Remove the color corresponding to the 4th signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCm0oVE_2zXm"
      },
      "source": [
        "Visualize the data after artifact removal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3p42C_1g2zXm"
      },
      "outputs": [],
      "source": [
        "# @title Visualize the data with artifacts second by second\n",
        "@widgets.interact(t=widgets.IntSlider(0, min=0, max=9))\n",
        "def plot_data_artifacts(t):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  # Define the time range for one second\n",
        "  time_range = np.arange(t, t+1, 1/fs)\n",
        "\n",
        "  # Compute the min and max values within the current time range\n",
        "  min_value = np.min(filtered_signals[:, int(t*fs):int((t+1)*fs)])\n",
        "  max_value = np.max(filtered_signals[:, int(t*fs):int((t+1)*fs)])\n",
        "\n",
        "  # Plot each signal in the time range\n",
        "\n",
        "  for i in range(filtered_signals.shape[0]):\n",
        "    if i > 1:\n",
        "        plt.plot(time_range, filtered_signals[i, int(t*fs):int((t+1)*fs)], color=colors[i], label=f'Channel {i+2}')\n",
        "    else:\n",
        "        plt.plot(time_range, filtered_signals[i, int(t*fs):int((t+1)*fs)], color=colors[i], label=f'Channel {i+1}')\n",
        "\n",
        "  plt.xlabel('Time (s)')\n",
        "  plt.xlim([t, t+1])\n",
        "  plt.ylim([min_value-1, max_value+1])\n",
        "  plt.gca().set_yticklabels([])  # Remove yticklabels\n",
        "  plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8sF7Glv2zXm"
      },
      "outputs": [],
      "source": [
        "# Plot the 4th signal before and after detrending\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(t, signals[3, :], label='Original', color=colors[2])\n",
        "plt.plot(t, filtered_signals[2, :], label='Detrended')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude (a.u.)')\n",
        "plt.xlim([0, 10])\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "GVG54h9lwS_Z"
      },
      "source": [
        "---\n",
        "# Section 2: Transforming a time series into the frequency domain\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 20 min*\n",
        "\n",
        "In this section, we will explore the transformation of temporal LFP signals into the frequency domain. Understanding the frequency composition of neural signals is crucial for uncovering patterns and extracting meaningful information from the data.\n",
        "\n",
        "Procedure:\n",
        "\n",
        "**Signal Transformation:**\n",
        "\n",
        "Utilize Fourier transforms to convert temporal signals into the frequency domain.\n",
        "\n",
        "**Power Spectral Density (PSD):**\n",
        "Calculate and visualize the Power Spectral Density to understand the distribution of signal power across different frequencies.\n",
        "\n",
        "**Interpretation:**\n",
        "Gain insights into the frequency components that dominate the LFP signals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ehWkAJO2zXm"
      },
      "source": [
        "## Loading real data from .mat files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bu7qrmy2zXp"
      },
      "source": [
        "The file LFPprobe.mat contains simultaneous recordings of 16 LFP channels from a NeuroNexus linear probe, with electrodes ranging from the parietal cortex to the hippocampus, spaced by 100 µm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqw_S7Hj2zXq"
      },
      "outputs": [],
      "source": [
        "# Import the necessary library\n",
        "from scipy.io import loadmat\n",
        "# Load the data from the .mat file\n",
        "probe_data = loadmat('LFPprobe.mat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcnQcdek2zXq"
      },
      "source": [
        "Inspecting the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU_pJU3a2zXq",
        "outputId": "27328680-8816-40ab-8416-2dcc057fb749"
      },
      "outputs": [],
      "source": [
        "# Explore the data\n",
        "print(probe_data.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP-OjrNp2zXq"
      },
      "source": [
        "Loading the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4WLNaxU2zXq",
        "outputId": "515ce65c-9381-461e-a04f-9f35a372219b"
      },
      "outputs": [],
      "source": [
        "probe_fs = probe_data['srate'].squeeze()  # Extract the sampling rate of the probe data\n",
        "probe_LFP = probe_data['LFPprobe']  # Extract the LFP data from the probe\n",
        "\n",
        "print(f\"The sampling rate of the probe data is {fs} Hz\")  # Print the sampling rate of the probe data\n",
        "print(f\"The shape of the probe data is {probe_LFP.shape}\")  # Print the shape of the probe data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3xLl4nTowS_a"
      },
      "source": [
        "### Computing the PSD using Welch's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "JfEpgjIhwS_a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('Probe PSD for channel 1')\n",
        "plt.plot(probe_LFP[0, 0:1000], 'royalblue')\n",
        "plt.xlabel('Time (ms)')\n",
        "plt.ylabel('Amplitude (µV)')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "probe_freqs, probe_psd = signal.welch(probe_LFP[0, :], fs=probe_fs, nperseg=1024)\n",
        "plt.plot(probe_freqs, probe_psd, color='royalblue')\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power (µV^2)')\n",
        "plt.xlim([0, 100])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0xTbSV0858A"
      },
      "source": [
        "Now doing it for all 16 channels of the probe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2Nv4tV62zXq"
      },
      "outputs": [],
      "source": [
        "probe_freqs, probe_psd = signal.welch(probe_LFP, fs=probe_fs, nperseg=1024)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.title('Probe PSD for all channels')\n",
        "plt.plot(probe_freqs, probe_psd.T, color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power')\n",
        "plt.xlim([0, 100])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr5iZGkd2zXq"
      },
      "source": [
        "#### Normalizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP85CMCf858B"
      },
      "source": [
        "Normalization can be a crucial step in signal processing that enhances the comparability of PSDs across different channels or experiments.\n",
        "\n",
        "The code below demonstrates three common normalization approaches applied to the PSD of probe Local Field Potential (LFP) signals:\n",
        "\n",
        "1. **Standard Normalization:**\n",
        "   - Normalizes the PSD by dividing each channel's power by its maximum power, providing a relative comparison of power levels.\n",
        "\n",
        "2. **dB Normalization:**\n",
        "   - Utilizes logarithmic scaling (dB) to normalize the PSD, enhancing visibility of power differences especially at lower values.\n",
        "\n",
        "3. **Z-scoring:**\n",
        "   - Z-scores the PSD, transforming it to a standard normal distribution by subtracting the mean and dividing by the standard deviation for each channel.\n",
        "\n",
        "Explore how these normalization techniques can change the visualization of the signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Het9nzpc2zXr"
      },
      "outputs": [],
      "source": [
        "probe_freqs, probe_psd = signal.welch(probe_LFP, fs=probe_fs, nperseg=1024)\n",
        "\n",
        "plt.figure(figsize=(8, 10))\n",
        "\n",
        "plt.subplot(4, 1, 1)  # Original Probe PSD for all channels\n",
        "plt.plot(probe_freqs, probe_psd.T, color='royalblue', alpha=0.5)\n",
        "plt.ylabel('Power (µV^2)')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.subplot(4, 1, 2)  # Standard Normalization\n",
        "plt.plot(probe_freqs, probe_psd.T / np.max(probe_psd, axis=1), color='royalblue', alpha=0.5)\n",
        "plt.ylabel('Normalized power')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.subplot(4, 1, 3)  # dB Normalization\n",
        "plt.plot(probe_freqs, 10 * np.log10(probe_psd.T / np.max(probe_psd, axis=1)), color='royalblue', alpha=0.5)\n",
        "plt.ylabel('Power (dB)')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.subplot(4, 1, 4)  # Z-scoring\n",
        "plt.plot(probe_freqs, (probe_psd.T - np.mean(probe_psd, axis=1)) / np.std(probe_psd, axis=1), color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Z-scored power')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COY-sHz02zXr"
      },
      "source": [
        "### The PSD usually varies with time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOFldVJ858B"
      },
      "source": [
        "Acknowledging that the PSD of neural signals typically varies over time is crucial. This variation forms the basis for the upcoming Time-Frequency Analysis section, where we introduce methods to capture and interpret the dynamic changes in frequency content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnCKXjW52zXr"
      },
      "outputs": [],
      "source": [
        "# Power spectral density of an artificial signal\n",
        "\n",
        "fs = 1000.  # Sampling frequency\n",
        "dt = 1./fs  # Time step\n",
        "t = np.arange(dt,5.00001,dt)  # Time array\n",
        "\n",
        "LFP = np.sin(2*np.pi*8*t)  # Generate artificial signal\n",
        "LFP[:2500] = 0  # Set initial portion to 0\n",
        "LFP = LFP + 0.7*np.sin(2*np.pi*20*t)  # Add another sinusoid\n",
        "\n",
        "plt.figure(figsize=(12,8))  # Create a figure\n",
        "ax1 = plt.subplot2grid((6,1),(0,0),rowspan=2)  # Define subplot for time series\n",
        "ax1.plot(t,LFP, color='royalblue')  # Plot the artificial signal\n",
        "ax1.set_xlabel('Time (s)')  # Set x-axis label\n",
        "ax1.set_xlim([0,5])  # Set x-axis limits\n",
        "\n",
        "win = 0.5*fs  # Define window length\n",
        "overlap = 0.5*win  # Define overlap\n",
        "nfft = 5000  # Define number of FFT points\n",
        "\n",
        "F,Pxx = signal.welch(LFP,fs,nperseg=win,noverlap=overlap,nfft=nfft)  # Compute Welch's method\n",
        "\n",
        "ax2 = plt.subplot2grid((6,1),(3,0),rowspan=3)  # Define subplot for power spectral density\n",
        "ax2.plot(F,Pxx,'ko-')  # Plot the power spectral density\n",
        "ax2.set_xlabel('Frequency (Hz)')  # Set x-axis label\n",
        "ax2.set_ylabel('Power (a.u.)')  # Set y-axis label\n",
        "ax2.set_xlim([0,30])  # Set x-axis limits\n",
        "plt.show()  # Display the plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-CiXIjE2zXr"
      },
      "source": [
        "---\n",
        "# Section 3: Time-Frequency Analyses\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 30 min*\n",
        "\n",
        "This section focuses on computing spectrograms, revealing the time-frequency profile of spectral power in LFP data. Spectrograms provide a dynamic view of neural activity, allowing us to uncover patterns that evolve over time.\n",
        "\n",
        "Procedure:\n",
        "\n",
        "**Spectrogram Calculation:**\n",
        "Utilize time-frequency analysis techniques to compute the spectrogram of LFP signals.\n",
        "\n",
        "**Visualization:**\n",
        "Create visualizations that represent the time-dependent changes in spectral power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yfHzhlR858C"
      },
      "source": [
        "Let's start by computing and visualizing a spectrogram of the signal we just saw at the end of section 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8Vn9XNg2zXr"
      },
      "outputs": [],
      "source": [
        "windowlen = int(2.*fs)      # Define window length in seconds\n",
        "stepsize  = int(0.1*windowlen) # Calculate percentage of overlapping\n",
        "Nwindows  = int((len(LFP)-windowlen)/stepsize+1)  # Calculate the number of windows\n",
        "\n",
        "T = np.empty(Nwindows)  # Initialize array to store time values\n",
        "TFD = np.empty((Nwindows,round(len(t)/2+1)))  # Initialize array to store time-frequency data\n",
        "for nwin in range(Nwindows):  # Iterate over each window\n",
        "    winsample = np.arange(windowlen) + (nwin-1)*stepsize  # Define the sample window\n",
        "    F,Pxx = signal.welch(LFP[winsample],fs=fs,nperseg=windowlen,nfft=nfft)  # Compute Welch's method\n",
        "    T[nwin] = t[int(winsample[int(windowlen/2)])]  # Store the time value\n",
        "    TFD[nwin,:] = Pxx  # Store the power spectral density\n",
        "\n",
        "plt.figure(figsize=(12,6))  # Create a figure for the spectrogram\n",
        "plt.pcolormesh(T,F,TFD.T)  # Plot the spectrogram\n",
        "plt.ylim([0,30])  # Set the y-axis limit\n",
        "plt.xlabel('Time (s)]')  # Set the x-axis label\n",
        "plt.ylabel('Frequency (Hz)')  # Set the y-axis label\n",
        "plt.colorbar(label='Power (a.u.)')  # Add colorbar\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3bNWQ1X2zXr"
      },
      "source": [
        "### Visualizing the frequency power changes through time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_gYRpplp2zXr"
      },
      "outputs": [],
      "source": [
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "@widgets.interact(epoch=widgets.IntSlider(0, min=0, max=TFD.shape[0]-1, step=1))\n",
        "def update_plot(epoch):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.xlabel('Frequency (Hz)')\n",
        "    plt.ylabel('Power')\n",
        "    plt.plot(F,TFD[int(epoch),:])\n",
        "    plt.xlim([0,30])\n",
        "    plt.ylim([0,1])\n",
        "    plt.title('Time = '+str(T[epoch])+' s')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDTNVMl_858C"
      },
      "source": [
        "Now simply using the spectrogram function from scipy.signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ8XDxKm2zXs"
      },
      "outputs": [],
      "source": [
        "# Using the spectrogram function\n",
        "\n",
        "# Define parameters for the spectrogram\n",
        "window_length = 1*fs  # length of the window in seconds\n",
        "overlap = 0.9*window_length  # overlap between consecutive windows\n",
        "nfft = 2**13  # number of data points used in each block for the FFT\n",
        "\n",
        "# Compute the spectrogram\n",
        "F, T, Sxx = signal.spectrogram(LFP, fs, nperseg=int(window_length), noverlap=overlap, nfft=nfft)\n",
        "\n",
        "# Visualize the spectrogram\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.pcolormesh(T, F, Sxx)\n",
        "plt.ylim([0,30])\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.colorbar(label='Power (a.u.)');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w82hnlJV2zXs"
      },
      "source": [
        "---\n",
        "# Section 4: Computing Phase Coherence\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 35 min*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYDca40q2zXs"
      },
      "source": [
        "In this section, we dive into the computation of phase coherence, a crucial measure in neuroscience for assessing the synchronization between different Local Field Potential (LFP) signals. Phase coherence provides valuable insights into the coordination of neural activity across multiple regions, shedding light on the underlying functional connectivity.\n",
        "\n",
        "Let's explore the steps involved in computing phase coherence and gain a deeper understanding of its significance in the context of mesoscopic neural dynamics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JI1xS8j2zXs"
      },
      "outputs": [],
      "source": [
        "# Compute the coherence value for a single frequency\n",
        "\n",
        "# Define the two frequencies\n",
        "freq1 = 8\n",
        "freq2 = 30\n",
        "fs = 1000\n",
        "\n",
        "\n",
        "\n",
        "# Create the time vector\n",
        "t = np.arange(0, 10, 1/fs)\n",
        "\n",
        "# Generate random noise\n",
        "noise = np.random.normal(0, 0.5, len(t)) # mean, SD, length\n",
        "\n",
        "phi   = -np.deg2rad(180) # Phase difference of 180 degrees\n",
        "rand_phi = np.random.uniform(0, 2*np.pi, len(t)) # Random phase differences\n",
        "\n",
        "# Create two signals\n",
        "signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t) + noise\n",
        "# Added phase difference to the second frequency in signal2\n",
        "signal2 = 2* np.sin(2 * np.pi * freq1 * t + phi) + 2 * np.sin(2*np.pi*freq2*t + rand_phi) + noise\n",
        "\n",
        "# Set parameters for the coherence function\n",
        "noverlap = 0.5*fs # Amount of overlap between windows\n",
        "nfft = 2**13 # Number of points to compute the FFT- the larger the better the frequency resolution\n",
        "nperseg = window_length # Number of points per segment\n",
        "\n",
        "# Compute the coherence between the two signals\n",
        "frequencies, coherence = signal.coherence(signal1, signal2, fs=fs,\n",
        "                                          nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
        "\n",
        "# Plot the signals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(t, signal1)\n",
        "plt.plot(t, signal2)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude (a.u.)')\n",
        "plt.xlim([0, 1])\n",
        "\n",
        "# Plot the coherence\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(frequencies, coherence)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Coherence')\n",
        "plt.xlim([0, 100])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OCZBCNvI2zXs"
      },
      "outputs": [],
      "source": [
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "@widgets.interact(noverlap=widgets.FloatSlider(0.5,min=0, max=1, step=0.1),\n",
        "               nfft=widgets.IntSlider(1024, min=1024, max=2**15, step=1024),\n",
        "               nperseg=widgets.IntSlider(1*fs, min=25, max=fs, step=1))\n",
        "\n",
        "\n",
        "# Interactive function to compute and plot coherence\n",
        "def interactive_coherence(noverlap, nfft, nperseg):\n",
        "    # Compute the coherence between the two signals\n",
        "    frequencies, coherence = signal.coherence(signal1, signal2, fs=fs,\n",
        "                                              nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
        "\n",
        "    # Plot the signals\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(t, signal1)\n",
        "    plt.plot(t, signal2)\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude (a.u.)')\n",
        "    plt.xlim([0, 1])\n",
        "\n",
        "    # Plot the coherence\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(frequencies, coherence)\n",
        "    plt.xlabel('Frequency (Hz)')\n",
        "    plt.ylabel('Coherence')\n",
        "    plt.xlim([0, 100])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jog-3Yz-2zXs"
      },
      "source": [
        "#### Coherence also varies in time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN1m8dwN858D"
      },
      "source": [
        "It's important to note that coherence, alongside the other signal properties we have explored until now, also exhibits temporal variations. Below is an example signal with varying levels of coherence in time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjZ2bqNb2zXs"
      },
      "outputs": [],
      "source": [
        "# Compute the coherence value for a single frequency\n",
        "\n",
        "# Define the two frequencies\n",
        "freq1 = 8\n",
        "freq2 = 30\n",
        "fs = 1000\n",
        "\n",
        "# Create the time vector\n",
        "t = np.arange(0, 10, 1/fs)\n",
        "\n",
        "# Generate random noise\n",
        "noise = np.random.normal(0, 0.2, len(t)) # mean, SD, length\n",
        "\n",
        "# Phase difference of 180 degrees from seconds 1 to 4\n",
        "phi = np.ones_like(t) * -np.deg2rad(180)\n",
        "phi[(t >= 1) & (t < 4)] = np.random.uniform(0, 2*np.pi, len(t[(t >= 1) & (t < 4)]))\n",
        "rand_phi = np.random.uniform(0, 2*np.pi, len(t)) # Random phase differences\n",
        "\n",
        "\n",
        "# Create two signals\n",
        "signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t) + noise\n",
        "signal2 = 2* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t + phi) + noise # Added phase difference to the second frequency in signal2\n",
        "\n",
        "# Set parameters for the coherence function\n",
        "noverlap = 0.5*fs # Amount of overlap between windows\n",
        "nfft = 2**13 # Number of points to compute the FFT- the larger the better the frequency resolution\n",
        "nperseg = window_length # Number of points per segment\n",
        "\n",
        "# Compute the coherence between the two signals\n",
        "frequencies, coherence = signal.coherence(signal1, signal2, fs=fs,\n",
        "                                          nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
        "\n",
        "\n",
        "# Plot the signals\n",
        "plt.figure(figsize=(10, 9))\n",
        "plt.subplot(3, 1, 1)  # New subplot added\n",
        "plt.plot(t, signal1)\n",
        "plt.plot(t, signal2)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude (a.u.)')\n",
        "plt.xlim([0, 10])  # Changed to show entire duration\n",
        "\n",
        "plt.subplot(3, 1, 2)  # Original subplot\n",
        "plt.plot(t, signal1)\n",
        "plt.plot(t, signal2)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude (a.u.)')\n",
        "plt.xlim([0, 5])\n",
        "\n",
        "\n",
        "# Plot the coherence\n",
        "plt.subplot(3, 1, 3)  # Original subplot\n",
        "plt.plot(frequencies, coherence)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Coherence')\n",
        "plt.xlim([0, 100])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHliXuc32zXs"
      },
      "source": [
        "#### Meet the coherogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHUAumyV858D"
      },
      "source": [
        "Now to characterize the time-varying aspect of coherence, we will use two artificial signals with a regular phase difference only present in a given frequency (30 Hz) and in an specific time window (between 10 and 20s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnV55kkZ2zXs"
      },
      "outputs": [],
      "source": [
        "# Define the two frequencies\n",
        "freq1 = 8\n",
        "freq2 = 30\n",
        "fs = 1000\n",
        "\n",
        "# Create the time vector\n",
        "t = np.arange(0, 30, 1/fs)\n",
        "\n",
        "# Generate random noise\n",
        "noise = np.random.normal(0, 0.5, len(t)) # mean, SD, length\n",
        "\n",
        "# Random phase differences\n",
        "phi = np.random.uniform(0, 2*np.pi, len(t))\n",
        "# Regular phase difference of 180 degrees from 10 to 20 seconds\n",
        "phi[(t >= 10) & (t < 20)] = np.ones_like(t[(t >= 10) & (t < 20)]) * -np.deg2rad(180)\n",
        "rand_phi = np.random.uniform(0, 2*np.pi, len(t)) # Random phase differences\n",
        "\n",
        "# Create two signals\n",
        "signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t) + noise\n",
        "signal2 = 2* np.sin(2 * np.pi * freq1 * t + rand_phi) + 2 * np.sin(2*np.pi*freq2*t + phi) + noise\n",
        "\n",
        "\n",
        "\n",
        "# Set parameters for the coherence function\n",
        "win    = 5*fs # window size\n",
        "step   = 0.1*win # step size\n",
        "Nwin   = int((len(signal1)-win)/step+1)\n",
        "nfft   = 2**13 # Number of points to compute the FFT- the larger the better the frequency resolution\n",
        "cohwin = 1*fs # window within Cxy computation\n",
        "\n",
        "Coherogram = []  # Initialize an empty list to store the coherence values\n",
        "T = []  # Initialize an empty list to store the time values\n",
        "for nwin in range(Nwin):  # Iterate through the range of Nwin\n",
        "    temp = np.arange(win)+nwin*int(step)  # Create a temporary array of indices for the current window\n",
        "    F, Cxy = signal.coherence(signal1[temp],signal2[temp],fs=fs,nperseg=cohwin,nfft=nfft)  # Calculate coherence using the signals within the current window\n",
        "    Coherogram.append(Cxy.T)  # Append the coherence values to the Coherogram list\n",
        "    T.append(np.mean(temp/fs))  # Append the average time value for the current window to the T list\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.pcolormesh(T,F,np.transpose(Coherogram))\n",
        "plt.ylim([0,50])\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.colorbar(label='Coherence');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNNN9nO2zXt"
      },
      "source": [
        "---\n",
        "# Section 5: Calculating the Modulation Index between different frequencies\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 50 min*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsBQ36-x2zXt"
      },
      "source": [
        "Welcome to Section 5, where we explore the computation of the Modulation Index. This advanced analysis allows us to assess the interaction between signals of different frequencies, providing a nuanced perspective on how neural oscillations may modulate each other.\n",
        "\n",
        "The Modulation Index serves as a valuable tool in unraveling the complexities of mesoscopic neural dynamics, offering insights into frequency-specific interactions and potential coordination between distinct neural circuits.\n",
        "\n",
        "The file LFP_HG_HFO contains simultaneous recordings of 2 LFP channels positioned on two different hippocampal layers. These channels have been named lfpHG and lfgHFO.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg4Mb9ht858E"
      },
      "source": [
        "Exploring Phase-Amplitude Coupling (PAC)\n",
        "\n",
        "In the following code snippet, we load neural data containing High-Gamma (lfpHG) and High-Frequency Oscillation (lfpHFO) signals. We then proceed to explore Phase-Amplitude Coupling (PAC) – a phenomenon where the amplitude of a high-frequency signal is modulated by the phase of a lower-frequency signal.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. **Loading Data:**\n",
        "   - Importing lfpHG and lfpHFO signals from the provided dataset.\n",
        "\n",
        "2. **Signal Processing:**\n",
        "   - Applying bandpass filters to extract specific frequency components from the LFP signal.\n",
        "   - Calculating the phase and amplitude of the filtered signals using the Hilbert transform.\n",
        "\n",
        "3. **Visualization:**\n",
        "   - Creating subplots to showcase the original LFP signal, filtered phase, filtered amplitude, and the resulting phase-amplitude coupling.\n",
        "\n",
        "4. **Highlighting Specific Phase Range:**\n",
        "   - Identifying a specific phase range and highlighting corresponding regions in the phase and amplitude plots.\n",
        "\n",
        "This exploration sets the foundation for understanding how neural signals' phase and amplitude interact, offering insights into the  dynamics of Phase-Amplitude Coupling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBZkXTZz2zXt"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = loadmat('LFP_HG_HFO.mat')\n",
        "lfpHG = data['lfpHG'][0]\n",
        "lfpHFO = data['lfpHFO'][0]\n",
        "\n",
        "# Set the sampling rate and calculate the time vector\n",
        "srate = 1000\n",
        "dt = 1./srate\n",
        "t = dt*(np.arange(len(lfpHG)))\n",
        "\n",
        "# Define nyquist frequency\n",
        "nyq = 0.5*srate\n",
        "\n",
        "LFP = lfpHG  # Assign lfpHG to LFP for further processing\n",
        "\n",
        "b,a = signal.butter(3,[5./nyq,10./nyq],'bandpass')  # Design a bandpass filter for the phase signal\n",
        "filteredPhase = signal.filtfilt(b,a,LFP)  # Apply the bandpass filter to the LFP signal\n",
        "\n",
        "b,a = signal.butter(3,[60./nyq,100./nyq],'bandpass')  # Design a bandpass filter for the amplitude signal\n",
        "filteredAmp = signal.filtfilt(b,a,LFP)  # Apply the bandpass filter to the LFP signal\n",
        "\n",
        "phase = np.angle(signal.hilbert(filteredPhase))  # Calculate the phase of the filtered phase signal\n",
        "amp = abs(signal.hilbert(filteredAmp))  # Calculate the amplitude of the filtered amplitude signal\n",
        "\n",
        "# Associated indices for each phase bin\n",
        "I = (np.rad2deg(phase)>-180)*(np.rad2deg(phase)<-160)  # Define indices for a specific phase range\n",
        "\n",
        "plt.figure(figsize=(16,10))  # Create a new figure with a specific size\n",
        "plt.subplot(211)  # Create a subplot in a 2x1 grid for the first plot\n",
        "plt.plot(t,LFP,'k-')  # Plot the LFP signal\n",
        "plt.plot(t,filteredPhase-1,linewidth=2)  # Plot the filtered phase signal\n",
        "plt.plot(t,8*filteredAmp-1.9,linewidth=1)  # Plot the filtered amplitude signal\n",
        "plt.plot(t,8*amp-1.9,'C1',linewidth=2)  # Plot the amplitude signal\n",
        "plt.xlim(40,42)  # Set the x-axis limits\n",
        "plt.ylim(-3,1)  # Set the y-axis limits\n",
        "\n",
        "plt.subplot(212)  # Create a subplot in a 2x1 grid for the second plot\n",
        "plt.plot(t,phase,'C0.')  # Plot the phase signal\n",
        "plt.plot(t[I],phase[I],'r.')  # Highlight the phase within the specified range\n",
        "plt.xlim(40,42)  # Set the x-axis limits\n",
        "plt.xlabel('Time (s)',size=13)  # Set the x-axis label\n",
        "plt.yticks([-np.pi,-np.pi/2,0,np.pi/2,np.pi],['-$\\pi$','-$\\pi$/2',0,'$\\pi$/2','$\\pi$'])  # Set the y-axis ticks\n",
        "\n",
        "plt.subplot(211)  # Create a subplot in a 2x1 grid for the third plot\n",
        "plt.plot(t[I],8*amp[I]-1.9,'r.')  # Highlight the amplitude within the specified range\n",
        "plt.yticks([-0.5,0,0.5])  # Set the y-axis ticks\n",
        "plt.title('Mean Amplitude = '+str(np.mean(amp[I])),size=14)  # Set the title for the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEerKhsS858E"
      },
      "source": [
        "Analyzing Mean Amplitude for Each Phase Bin and the Modulation Index\n",
        "\n",
        "In the following code snippet, we extend our exploration of Phase-Amplitude Coupling (PAC) by examining the mean amplitude for specific phase bins. Additionally, we introduce an entropy-based Modulation Index to quantify the degree of amplitude modulation by phase.\n",
        "\n",
        "Here's a breakdown of the code:\n",
        "\n",
        "1. **Defining Phase Bins:**\n",
        "   - Creating a vector representing phase bins in 20-degree increments.\n",
        "\n",
        "2. **Mean Amplitude Calculation:**\n",
        "   - Iterating through phase bins to calculate the mean amplitude for each bin.\n",
        "\n",
        "3. **Visualization with Bar Plot:**\n",
        "   - Creating a bar plot to visualize the mean amplitude across different theta phase bins.\n",
        "\n",
        "4. **Entropy-Based Modulation Index:**\n",
        "   - Calculating the Modulation Index using entropy-based measures, providing a quantitative assessment of phase-amplitude coupling.\n",
        "\n",
        "This code helps to show that the amplitude of gamma oscillations varies across different phases of the theta rhythm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnB3t8xy2zXt"
      },
      "outputs": [],
      "source": [
        "# Mean amplitude for each phase bin\n",
        "\n",
        "# Define the phase vector\n",
        "phasevector = np.arange(-180,161,20)\n",
        "\n",
        "# Initialize an empty array for mean amplitude\n",
        "MeanAmp = np.empty(len(phasevector))\n",
        "\n",
        "# Calculate the mean amplitude for each phase bin\n",
        "for count,phasebin in enumerate(phasevector):\n",
        "    I = (np.rad2deg(phase)>phasebin)*(np.rad2deg(phase)<phasebin+20)\n",
        "    MeanAmp[count] = np.mean(amp[I])\n",
        "\n",
        "# Create a bar plot to visualize the mean amplitude\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(np.arange(10,711,20),np.concatenate((np.array(MeanAmp),np.array(MeanAmp))),\n",
        "        20,color='r',edgecolor='k')\n",
        "plt.xticks(np.arange(0,721,90))\n",
        "plt.xlabel('Theta Phase (^o)',size=13)\n",
        "plt.ylabel('Mean $\\gamma$ Amplitude (mV)',size=13)\n",
        "plt.xlim(0,720)\n",
        "\n",
        "# Calculate the entropy-based modulation index\n",
        "p = MeanAmp/sum(MeanAmp)\n",
        "H = -sum(p[p>0]*np.log(p[p>0]))\n",
        "N = len(MeanAmp)\n",
        "MI = (np.log(N)-H)/np.log(N)\n",
        "plt.title('Modulation Index = '+str(MI),size=14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew9v0b14858E"
      },
      "source": [
        "Exploring Phase-Amplitude Comodulogram\n",
        "\n",
        "In this final code snippet, we integrate the concepts of Phase-Amplitude Coupling (PAC) into a comodulogram, providing a comprehensive visualization of how the modulation index varies across different phase and amplitude frequency combinations.\n",
        "\n",
        "Here's an overview of the code:\n",
        "\n",
        "1. **Frequency Vectors and Parameters:**\n",
        "   - Define frequency vectors for phase and amplitude, along with bandwidth parameters.\n",
        "\n",
        "2. **Initialization:**\n",
        "   - Initialize arrays to store mean amplitude and the comodulogram.\n",
        "\n",
        "3. **Nested Looping:**\n",
        "   - Iterate through phase and amplitude frequency vectors.\n",
        "   - Apply bandpass filters to obtain phase and amplitude signals.\n",
        "   - Calculate the modulation index for each phase bin.\n",
        "\n",
        "4. **Comodulogram Construction:**\n",
        "   - Populate the comodulogram array with modulation indices for various phase and amplitude frequency combinations.\n",
        "\n",
        "This comodulogram serves as a powerful tool for visualizing the possible relationships between different frequency components in neural oscillations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFJMuvPw2zXt"
      },
      "outputs": [],
      "source": [
        "# Phase-Amplitude comodulogram\n",
        "LFP = lfpHG\n",
        "\n",
        "phase_freq_vector = np.arange(1.,20.,2.)\n",
        "fp_bandwidth = 4\n",
        "amp_freq_vector = np.arange(20.,201.,5.)\n",
        "fa_bandwidth = 10\n",
        "\n",
        "MeanAmp = np.empty(len(phasevector))  # Initialize an empty array for mean amplitude\n",
        "Comodulogram = np.empty((len(phase_freq_vector),len(amp_freq_vector)))  # Initialize an empty array for the comodulogram\n",
        "\n",
        "for count_phase,fp in enumerate(phase_freq_vector):  # Loop through the phase frequency vector\n",
        "    b,a = signal.butter(3,[fp/nyq,(fp+fp_bandwidth)/nyq],'bandpass')  # Apply a Butterworth filter to the phase signal\n",
        "    filteredPhase = signal.filtfilt(b,a,LFP)  # Filter the LFP signal\n",
        "    phase = np.angle(signal.hilbert(filteredPhase))  # Calculate the phase of the filtered signal\n",
        "\n",
        "    for count_amp,fa in enumerate(amp_freq_vector):  # Loop through the amplitude frequency vector\n",
        "        b,a = signal.butter(3,[fa/nyq,(fa+fa_bandwidth)/nyq],'bandpass')  # Apply a Butterworth filter to the amplitude signal\n",
        "        filteredAmp = signal.filtfilt(b,a,LFP)  # Filter the LFP signal\n",
        "        amp = abs(signal.hilbert(filteredAmp))  # Calculate the amplitude of the filtered signal\n",
        "\n",
        "        for count,phasebin in enumerate(phasevector):  # Loop through the phase vector\n",
        "            I = (np.rad2deg(phase)>phasebin)*(np.rad2deg(phase)<(phasebin+20))  # Define the index for the specified phase range\n",
        "            MeanAmp[count] = np.mean(amp[I])  # Calculate the mean amplitude within the specified phase range\n",
        "\n",
        "        p = MeanAmp/sum(MeanAmp)  # Calculate the probability distribution\n",
        "        MI = (np.log(len(p))+sum(p[p>0]*np.log(p[p>0])))/np.log(len(p))  # Calculate the modulation index\n",
        "        Comodulogram[count_phase,count_amp] = MI  # Store the modulation index in the comodulogram array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKNvf_Np2zXt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.contourf(phase_freq_vector+fp_bandwidth/2.,amp_freq_vector+fa_bandwidth/2.,Comodulogram.T,30)\n",
        "plt.xlabel('Phase Frequency (Hz)',size=13)\n",
        "plt.ylabel('Amplitude Frequency (Hz)',size=13)\n",
        "plt.colorbar(label=\"Modulation Index\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3KSapdYRwS_a"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "\n",
        "Congratulations on completing this micro-course on local field potential (LFP) analysis with open-source tools! Throughout this notebook, we delved into the fundamental aspects of signal processing and oscillation analyses in neuroscience. Let's recap the key highlights:\n",
        "\n",
        "## Key Learnings:\n",
        "\n",
        "1. **Visualizing Raw Signals and Identifying Artifacts:**\n",
        "   - Explored techniques for visualizing raw LFP signals and detecting artifacts that could impact subsequent analyses.\n",
        "\n",
        "2. **Transforming Signals: Temporal to Frequency Domain:**\n",
        "   - Mastered the transformation of temporal LFP signals into the frequency domain, gaining insights into the spectral composition of neural activity.\n",
        "\n",
        "3. **Computing Time-Frequency Profiles (Spectrogram):**\n",
        "   - Learned to compute spectrograms, revealing the dynamic changes in spectral power over time and providing a comprehensive view of neural oscillations.\n",
        "\n",
        "4. **Calculating Phase Coherence Between Signals:**\n",
        "   - Explored the computation of phase coherence, a vital measure for understanding synchronization between different LFP signals.\n",
        "\n",
        "5. **Determining Modulation Index Between Signals of Different Frequencies:**\n",
        "   - Investigated advanced analyses by calculating modulation indices between signals of distinct frequencies, uncovering intricate interactions in neural circuits.\n",
        "\n",
        "\n",
        "## Next Steps:\n",
        "\n",
        "This micro-course serves as a foundation for further exploration into the vast field of neuroscientific signal analysis. Consider applying these principles to real-world datasets and extending your knowledge into more advanced topics such as connectivity analysis, feature extraction, and machine learning applications in neuroscience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "B7xai9zLwS_a"
      },
      "source": [
        "---\n",
        "# Supplementary Materials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RIEwJoa1wS_a"
      },
      "source": [
        "## Databases:\n",
        "\n",
        "Explore openly available neural electrophysiology data from various websites for your research:\n",
        "\n",
        "- [CRCNS](crcns.org)\n",
        "- [IBL's Brainwide Map](https://www.internationalbrainlab.com/data)\n",
        "- [Zenodo](https://zenodo.org)\n",
        "- [figshare](figshare.com)\n",
        "- [Dryad](https://datadryad.org/stash)\n",
        "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
        "\n",
        "## Resources from the Open-Source Community:\n",
        "\n",
        "Discover valuable resources from the open-source community related to neuroscience:\n",
        "\n",
        "- [List of Neuroscience Databases](en.wikipedia.org/wiki/List_of_neuroscience_databases)\n",
        "- [NeuralEnsemble](http://neuralensemble.org)\n",
        "- [Open Computational Neuroscience Resources](https://github.com/asoplata/open-computational-neuroscience-resources)\n",
        "\n",
        "## Learning Materials:\n",
        "\n",
        "Enhance your knowledge with these learning materials:\n",
        "\n",
        "- [Analyzing Neural Time Series Data: Theory and Practice (Mike Cohen's book)](https://direct.mit.edu/books/book/4013/Analyzing-Neural-Time-Series-DataTheory-and)\n",
        "- [Mike X Cohen YT videos on signal processing for neuroscience](https://www.youtube.com/@mikexcohen1/playlists)\n",
        "- [Signal Analysis 2020.2 (Prof. Tort's Signal Analysis course repo on GitHub)](https://github.com/tortlab/SignalAnalysis2020.2)\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
