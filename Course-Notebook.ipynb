{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p04tD5372zXf"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lucaase/LFP-analysis-HS/blob/main/Course-Notebook.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "wnw2RlnOwS_R"
      },
      "source": [
        "# **Local field potential analysis with open source tools**\n",
        "\n",
        "Welcome to the 2023 House Symposium of the Brain Institute! This short tutorial is designed to be part of the symposium, offering a comprehensive introduction to the intriguing realm of signal processing and oscillation analyses in neuroscience. Our focus will be on leveraging open-source tools to unravel the mysteries encoded in data recorded at the mesoscopic scale â€“ the Local Field Potential (LFP). The LFP serves as a dynamic window into the activity of a small, localized population of neurons proximate to the recording electrode.\n",
        "\n",
        "**Brain Intitute, Federal University of Rio Grande do Norte**\n",
        "\n",
        "**Content creators**: Lucas CS Tavares (lucastavares@neuro.ufrn.br), Rodrigo MM Santiago (rsantiago@neuro.ufrn.br)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HpnzigXzwS_U"
      },
      "source": [
        "___\n",
        "# Tutorial Objectives\n",
        "\n",
        "*Estimated timing of tutorial: 1h15 minutes*\n",
        "\n",
        "In this immersive tutorial, our primary goals are to equip attendees with the skills to dissect and interpret local field potential data through the lens of open-source tools. Throughout the session, participants will gain proficiency in the following key areas:\n",
        "\n",
        "- **Visualizing Raw Signals and Identifying Artifacts**:\n",
        "    - Explore techniques to visualize raw LFP signals effectively.\n",
        "    - Develop strategies for identifying and mitigating artifacts in the data.\n",
        "- **Transforming Signals: Temporal to Frequency Domain**:\n",
        "    - Learn how to transform temporal signals into the frequency domain.\n",
        "    - Understand the significance of frequency domain analysis in extracting meaningful insights.\n",
        "- **Computing Time-Frequency Profiles (Spectrogram)**:\n",
        "    - Learn the process of computing spectrograms to unveil the time-frequency profile of spectral power in LFP data.\n",
        "    - Gain insights into the dynamic changes in neural activity over time.\n",
        "- **Calculating Phase Coherence Between Signals**:\n",
        "    - Dive into the computation of phase coherence, a crucial measure for understanding synchronization between two signals.\n",
        "    - Uncover the interplay of neural activities reflected in phase relationships.\n",
        "- **Computing the Modulation Index Between Signals of Different Frequencies**:\n",
        "    - Explore advanced analyses by calculating modulation indices between signals of distinct frequencies.\n",
        "    - Understand how different frequency components interact and modulate each other.\n",
        "    \n",
        "\n",
        "<br>\n",
        "\n",
        "**Acknowledgements:**\n",
        "- We thank Prof. Adriano Tort. Much of today's tutorials are inspired by exercises assigned in his classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "9vQ43bs_wS_U"
      },
      "outputs": [],
      "source": [
        "# @title Tutorial slides\n",
        "# @markdown These are the slides for the videos in all tutorials today\n",
        "from IPython.display import IFrame\n",
        "link_id = \"2mkq4\"\n",
        "print(f\"If you want to download the slides: https://osf.io/download/{link_id}/\")\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "AKCJxi-SwS_V"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "5cD4uWVMwS_W"
      },
      "outputs": [],
      "source": [
        "# @title Import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "u9wk5eVBwS_W"
      },
      "outputs": [],
      "source": [
        "# @title Figure Settings\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').disabled = True\n",
        "\n",
        "import ipywidgets as widgets  # interactive display\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mfUPJnSNwS_X"
      },
      "source": [
        "---\n",
        "# Section 1: Visualizing the signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-CsQRzS6wS_Y"
      },
      "source": [
        "In this section, we will delve into the essential step of visualizing raw Local Field Potential (LFP) signals and developing techniques to identify and mitigate artifacts. Visualization is a critical first step in understanding the characteristics of our data and ensuring its reliability for subsequent analyses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "vwrZKMDzwS_Y"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "# @markdown Execute this cell to generate some simulated data. The data is a sum of two sine waves with different frequencies and amplitudes, plus some noise\n",
        "\n",
        "# Setting random seed for reproducibility\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Sampling rate\n",
        "fs = 1000\n",
        "# Time vector of 1 second\n",
        "t = np.arange(0, 1, 1/fs)\n",
        "\n",
        "# Generate two sine waves with different frequencies and amplitudes\n",
        "freq1 = 8 # 8 Hz, or 8 cycles per second\n",
        "freq2 = 30\n",
        "amp1 = 2 # The amplitude of the sine wave\n",
        "amp2 = 1\n",
        "\n",
        "# Generate random noise\n",
        "noise = np.random.normal(0, 0.5, len(t)) # mean, SD, length\n",
        "\n",
        "# Generate signal\n",
        "LFP = amp1 * np.sin(2*np.pi*freq1*t) + amp2 * np.sin(2*np.pi*freq2*t) + noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q9RaltTF2zXj"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "\n",
        "# @markdown Execute this cell to visualize the data\n",
        "\n",
        "# Plot the signal\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.title('Synthetic signal')\n",
        "plt.plot(t, LFP, 'royalblue')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([-6, 6])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhgjTdDO2zXj"
      },
      "source": [
        "## Interactive Demo 1: Playing with signal parameters\n",
        "\n",
        "Using an interactive widget, we can visualize how the manually inserted frequencies are present in the signal, how their amplitudes change and the effect of noise in the time series. This, however, is an overly simplistic representation, as the real signals can be decomposed into indefinite (limited by the sampling rate) frequency components.\n",
        "\n",
        "While decoupling signal from noise in this example is as simple as moving a slider, in the real world it is one of the hardest challenges in neuroscience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MKlkxq0q2zXj"
      },
      "outputs": [],
      "source": [
        "# @title Make sure you execute this cell to enable the widget!\n",
        "\n",
        "@widgets.interact(freq1=widgets.IntSlider(8, min=1, max=100),\n",
        "                  freq2=widgets.IntSlider(30, min=1, max=100),\n",
        "                  amp1=widgets.IntSlider(2, min=1, max=5),\n",
        "                  amp2=widgets.IntSlider(1, min=1, max=5),\n",
        "                  noise=widgets.FloatSlider(0.5, min=0, max=1.0))\n",
        "\n",
        "def plot_data_estimate(freq1, freq2, amp1, amp2, noise):\n",
        "  t = np.arange(0, 1, 1/fs)\n",
        "  LFP = amp1 * np.sin(2*np.pi*freq1*t) + amp2 * np.sin(2*np.pi*freq2*t) + np.random.normal(0, noise, len(t))\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.plot(t, LFP, 'royalblue')\n",
        "  plt.xlabel('Time (seconds)')\n",
        "  plt.ylabel('Amplitude')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([-6, 6])\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roBN4RCD2zXj"
      },
      "source": [
        "#### Sampling rate and aliasing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNUDRity2zXj"
      },
      "source": [
        "This section will showcase the effects that different sampling rates can produce on the recorded signal, and how it can lead to aliasing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsFGGTkV2zXk"
      },
      "outputs": [],
      "source": [
        "# Create a 3x1 figure\n",
        "fig, axs = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "# Plot the original signal\n",
        "axs[0].plot(t, LFP, 'royalblue')\n",
        "axs[0].set_title('Original signal')\n",
        "axs[0].set_xlabel('Time (seconds)')\n",
        "axs[0].set_ylabel('Amplitude')\n",
        "\n",
        "# Subsample the signal at 100 Hz (every 10th sample)\n",
        "sub_LFP = LFP[::10]\n",
        "sub_t = t[::10]\n",
        "\n",
        "# Plot the original signal with subsampling points\n",
        "axs[1].plot(t, LFP, 'royalblue')\n",
        "axs[1].plot(sub_t, sub_LFP, 'ko')\n",
        "axs[1].set_title('Original signal with subsampling points')\n",
        "axs[1].set_xlabel('Time (seconds)')\n",
        "axs[1].set_ylabel('Amplitude')\n",
        "\n",
        "# Plot the subsampled signal\n",
        "axs[2].plot(sub_t, sub_LFP, 'royalblue')\n",
        "axs[2].set_title('Subsampled signal')\n",
        "axs[2].set_xlabel('Time (seconds)')\n",
        "axs[2].set_ylabel('Amplitude')\n",
        "\n",
        "# Show the figure\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPKfgadB2zXk"
      },
      "source": [
        "**Aliasing** is a phenomenon in signal processing where a high-frequency signal appears as a lower-frequency signal in the sampled data. This mischaracterization occurs when the sampling rate used to capture a signal is insufficient to accurately represent the original analog signal. Aliasing can lead to a misinterpretation of the true frequency content of the signal and introduce artifacts in the reconstructed signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6UUNY1Kn2zXk"
      },
      "outputs": [],
      "source": [
        "# @title An interactive widget with sliders for frequency and subsampling rate\n",
        "@widgets.interact(freq=widgets.IntSlider(2, min=1, max=100),\n",
        "                  subsample_rate=widgets.IntSlider(100, min=1, max=100))\n",
        "\n",
        "def plot_data_estimate(freq, subsample_rate):\n",
        "  # Generate the time vector\n",
        "  t = np.arange(0, 1, 1/fs)\n",
        "\n",
        "  # Generate the original signal\n",
        "  LFP = np.sin(2*np.pi*freq*t)\n",
        "\n",
        "  # Subsample the signal\n",
        "  sub_LFP = LFP[::subsample_rate]\n",
        "  sub_t = t[::subsample_rate]\n",
        "\n",
        "  # Create a 3x1 figure\n",
        "  fig, axs = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "  # Plot the original signal\n",
        "  axs[0].plot(t, LFP, 'royalblue')\n",
        "  axs[0].set_title('Original signal')\n",
        "  axs[0].set_xlabel('Time (seconds)')\n",
        "  axs[0].set_ylabel('Amplitude')\n",
        "\n",
        "  # Plot the original signal with subsampling points\n",
        "  axs[1].plot(t, LFP, 'royalblue')\n",
        "  axs[1].plot(sub_t, sub_LFP, 'ko')\n",
        "  axs[1].set_title('Original signal with subsampling points')\n",
        "  axs[1].set_xlabel('Time (seconds)')\n",
        "  axs[1].set_ylabel('Amplitude')\n",
        "\n",
        "  # Plot the subsampled signal\n",
        "  axs[2].plot(sub_t, sub_LFP, 'royalblue')\n",
        "  axs[2].set_title('Subsampled signal')\n",
        "  axs[2].set_xlabel('Time (seconds)')\n",
        "  axs[2].set_ylabel('Amplitude')\n",
        "\n",
        "  # Show the figure\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbtXBHD52zXk"
      },
      "source": [
        "When a continuous analog signal is sampled at a certain rate, it is converted into a discrete signal by capturing its amplitude at regular intervals. The Nyquist-Shannon sampling theorem states that to avoid aliasing, the sampling rate must be at least twice the frequency of the highest component in the signal. This critical frequency is known as the **Nyquist frequency**.\n",
        "\n",
        "#### Mitigation Strategies:\n",
        "\n",
        "To mitigate aliasing, it is crucial to adhere to the Nyquist sampling criterion by choosing an appropriate sampling rate. If the frequency of a signal exceeds half of the sampling rate, a low-pass anti-aliasing filter can be employed before sampling to remove high-frequency components. This ensures that signals are accurately represented in the digital domain and prevents the introduction of misleading oscillations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXTqhSI_2zXk"
      },
      "source": [
        "## Signal artifacts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gsAiptr_wS_Y"
      },
      "source": [
        "### Introduction to Introducing Artifacts and Artifact Corrections\n",
        "\n",
        "In our exploration, we will intentionally introduce some artifacts into our synthetic signal to observe their impact and subsequently apply artifact correction techniques. Artifacts manifest as undesired features in a signal, such as an overall increase in amplitude, non-stationarity*, or the presence of fixed power in spurious frequencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9oqpLTj2zXk"
      },
      "source": [
        "We will start by generating 5 synthetic signals, which will be our \"channels\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K624C3Ic2zXk"
      },
      "outputs": [],
      "source": [
        "from cycler import cycler\n",
        "\n",
        "# Define your custom color cycle\n",
        "colors = ['royalblue', 'seagreen', 'goldenrod', 'violet', 'firebrick']\n",
        "custom_cycler = cycler(color=colors)\n",
        "\n",
        "t = np.arange(0, 10, 1/fs)\n",
        "n_trials = 5\n",
        "# Generate signals in an array\n",
        "signals = np.zeros((n_trials, len(t)))\n",
        "\n",
        "# Initialize the frequency vector\n",
        "frequencies = np.arange(0.1, 100, 0.1)\n",
        "# Initialize the amplitude vector (for simplicity, we will assume that the amplitudes are the inverse of the frequencies)\n",
        "amplitudes = 1 / frequencies\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  # assign a random amplitude between 1 and 5\n",
        "  amp = amplitudes[np.random.randint(0, len(frequencies))]\n",
        "  # assign a random frequency between 1 and 100\n",
        "  freq = frequencies[np.random.randint(0, len(frequencies))]\n",
        "  # generate signal\n",
        "  signals[i, :] = (amp * np.sin(2*np.pi*freq*t) + amp * np.sin(2*np.pi*freq*t) + np.random.normal(0, 0.5, len(t))) + 2.5*i  # add noise and a constant value to separate signals\n",
        "\n",
        "# Plot the signals without overlaying them\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "ax.set_prop_cycle(custom_cycler)\n",
        "plt.title('Synthetic signals')\n",
        "plt.plot(t, signals.T)  # Use the fixed colors for each signal\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Channel #')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([-2, 12])  # Adjust y-axis limit to accommodate the constant values\n",
        "plt.gca().set_yticklabels([])  # Remove yticklabels\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC_qkrDe2zXk"
      },
      "source": [
        "#### Common Types of Artifacts\n",
        "\n",
        "1. **Overall Increase in Amplitude:**\n",
        "   - This artifact is characterized by a global rise in signal amplitude, often obscuring the underlying patterns of interest.\n",
        "   - Most of the time, this happens due to behaviours outside the scope of the analysed phenomena, such as blinking, motor activity, etc.\n",
        "   \n",
        "2. **Non-Stationarity:**\n",
        "   - Non-stationarity refers to variations in the statistical properties of the signal over time. These variations can hinder the accurate analysis of underlying dynamics.\n",
        "\n",
        "3. **Fixed Power in Spurious Frequencies:**\n",
        "   - Artifacts may introduce power at specific frequencies unrelated to the natural frequency content of the signal, leading to misleading interpretations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyfTi6dm2zXl"
      },
      "outputs": [],
      "source": [
        "# Adding artifacts to the data\n",
        "\n",
        "# Increase the amplitude of the third signal from 2.5s to 4.5s\n",
        "signals[2, int(2.5*fs):int(4.5*fs)] = signals[2, int(2.5*fs):int(4.5*fs)] + 4\n",
        "\n",
        "# Create a trend (linear increase) in signal 4\n",
        "signals[3, :] = signals[3, :] + np.linspace(0, 10, len(t))\n",
        "\n",
        "# Increase the power of 60Hz in all signals from 5.5s to 5.9s\n",
        "signals[:, int(5.5*fs):int(5.9*fs)] += 0.5*np.sin(2*np.pi*60*t[int(5.5*fs):int(5.9*fs)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_72jmBjm2zXl"
      },
      "source": [
        "Visualizing the data after artifact insertions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EUDQi67k2zXl"
      },
      "outputs": [],
      "source": [
        "# @title Visualize the data with artifacts second by second\n",
        "@widgets.interact(t=widgets.IntSlider(0, min=0, max=9))\n",
        "def plot_data_artifacts(t):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  # Define the time range for one second\n",
        "  time_range = np.arange(t, t+1, 1/fs)\n",
        "\n",
        "  # Compute the min and max values within the current time range\n",
        "  min_value = np.min(signals[:, int(t*fs):int((t+1)*fs)])\n",
        "  max_value = np.max(signals[:, int(t*fs):int((t+1)*fs)])\n",
        "\n",
        "  # Plot each signal in the time range\n",
        "  for i in range(signals.shape[0]):\n",
        "    plt.plot(time_range, signals[i, int(t*fs):int((t+1)*fs)], color=colors[i])\n",
        "\n",
        "  plt.xlabel('Time (seconds)')\n",
        "  plt.ylabel('Channel #')\n",
        "  plt.xlim([t, t+1])\n",
        "  plt.ylim([min_value-1, max_value+1])\n",
        "  plt.gca().set_yticklabels([])  # Remove yticklabels\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjWAGWRV2zXl"
      },
      "source": [
        "### Artifact Corrections\n",
        "\n",
        "Several techniques can be employed to mitigate the impact of artifacts and restore the integrity of the signal:\n",
        "\n",
        "#### 1. Detrending:\n",
        "   - **Purpose:** Remove long-term trends or baseline shifts in the signal.\n",
        "   - **Implementation:** Apply detrending algorithms to eliminate slow-varying components.\n",
        "\n",
        "#### 2. Notch Filter:\n",
        "   - **Purpose:** Target and eliminate power at specific frequencies, often associated with external interference.\n",
        "   - **Implementation:** Use notch filters to suppress unwanted frequency components.\n",
        "\n",
        "#### 3. Removing Defective Channels:\n",
        "   - **Purpose:** Address artifacts originating from specific recording channels.\n",
        "   - **Implementation:** Identify and exclude channels with significant artifacts from further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EjPCUs12zXl"
      },
      "source": [
        "Detrending a signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "meWp3HnQwS_Y"
      },
      "outputs": [],
      "source": [
        "# Import the necessary library\n",
        "import scipy.signal as signal\n",
        "\n",
        "# Initialize the filtered signals array\n",
        "filtered_signals = np.zeros(signals.shape)\n",
        "\n",
        "# Apply the detrending function to the 4th channel\n",
        "filtered_signals[3,:] = signal.detrend(signals[3, :],type='linear', axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fPEmpCy2zXl"
      },
      "source": [
        "Notch filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGqTPIqd2zXl"
      },
      "outputs": [],
      "source": [
        "# Applying a notch filter to remove line (60Hz) noise\n",
        "\n",
        "# Define the notch filter function\n",
        "def notch_filter(data, fs, freq, Q=30):\n",
        "    w0 = freq/(fs/2) # Normalized Frequency\n",
        "    b, a = signal.iirnotch(w0, Q) # Q is the quality factor\n",
        "    filtered_data = signal.filtfilt(b, a, data) # Apply the notch filter\n",
        "\n",
        "    return filtered_data\n",
        "\n",
        "# Apply the notch filter to each channel\n",
        "for i in range(signals.shape[0]):\n",
        "    filtered_signals[i, :] = notch_filter(signals[i, :], fs, freq=60) # Freq is the frequency to be removed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GCDo7u52zXm"
      },
      "source": [
        "Removing a bad channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLA6tlRU2zXm"
      },
      "outputs": [],
      "source": [
        "# Remove the 3rd channel from the filtered signals array\n",
        "filtered_signals = np.delete(filtered_signals, 2, axis=0)\n",
        "# Remove the corresponding color\n",
        "colors.pop(2)  # Remove the color corresponding to the 4th signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCm0oVE_2zXm"
      },
      "source": [
        "Visualize the data after artifact removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3p42C_1g2zXm"
      },
      "outputs": [],
      "source": [
        "# @title Visualize the data with artifacts second by second\n",
        "@widgets.interact(t=widgets.IntSlider(0, min=0, max=9))\n",
        "def plot_data_artifacts(t):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  # Define the time range for one second\n",
        "  time_range = np.arange(t, t+1, 1/fs)\n",
        "\n",
        "  # Compute the min and max values within the current time range\n",
        "  min_value = np.min(filtered_signals[:, int(t*fs):int((t+1)*fs)])\n",
        "  max_value = np.max(filtered_signals[:, int(t*fs):int((t+1)*fs)])\n",
        "\n",
        "  # Plot each signal in the time range\n",
        "\n",
        "  for i in range(filtered_signals.shape[0]):\n",
        "    plt.plot(time_range, filtered_signals[i, int(t*fs):int((t+1)*fs)], color=colors[i])\n",
        "\n",
        "  plt.xlabel('Time (seconds)')\n",
        "  plt.ylabel('Channel #')\n",
        "  plt.xlim([t, t+1])\n",
        "  plt.ylim([min_value-1, max_value+1])\n",
        "  plt.gca().set_yticklabels([])  # Remove yticklabels\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8sF7Glv2zXm"
      },
      "outputs": [],
      "source": [
        "# Plot the 4th signal before and after detrending\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(t, signals[3, :], label='Original')\n",
        "plt.plot(t, filtered_signals[3, :], label='Detrended')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlim([0, 10])\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "GVG54h9lwS_Z"
      },
      "source": [
        "---\n",
        "# Section 2: Transforming a time series into the frequency domain\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 20 min*\n",
        "\n",
        "In this section, we will explore the transformation of temporal LFP signals into the frequency domain. Understanding the frequency composition of neural signals is crucial for uncovering patterns and extracting meaningful information from the data.\n",
        "\n",
        "Procedure:\n",
        "\n",
        "**Signal Transformation:**\n",
        "\n",
        "Utilize Fourier transforms to convert temporal signals into the frequency domain.\n",
        "\n",
        "**Power Spectral Density (PSD):**\n",
        "Calculate and visualize the Power Spectral Density to understand the distribution of signal power across different frequencies.\n",
        "\n",
        "**Interpretation:**\n",
        "Gain insights into the frequency components that dominate the LFP signals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ehWkAJO2zXm"
      },
      "source": [
        "## Loading real data from .mat files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bu7qrmy2zXp"
      },
      "source": [
        "The file LFPprobe.mat contains simultaneous recordings of 16 LFP channels from a NeuroNexus vertical linear probe, with electrodes ranging from the parietal cortex to the hippocampus, spaced by 100um."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqw_S7Hj2zXq"
      },
      "outputs": [],
      "source": [
        "# Import the necessary library\n",
        "from scipy.io import loadmat\n",
        "# Load the data from the .mat file\n",
        "probe_data = loadmat('LFPprobe.mat')\n",
        "GC_data = loadmat('GC_LFPs.mat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcnQcdek2zXq"
      },
      "source": [
        "Inspecting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU_pJU3a2zXq"
      },
      "outputs": [],
      "source": [
        "# Explore the data\n",
        "print(probe_data.keys())\n",
        "print(GC_data.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP-OjrNp2zXq"
      },
      "source": [
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4WLNaxU2zXq"
      },
      "outputs": [],
      "source": [
        "probe_fs = probe_data['srate'].squeeze()  # Extract the sampling rate of the probe data\n",
        "probe_LFP = probe_data['LFPprobe']  # Extract the LFP data from the probe\n",
        "\n",
        "print(f\"The sampling rate of the probe data is {fs} Hz\")  # Print the sampling rate of the probe data\n",
        "print(f\"The shape of the probe data is {probe_LFP.shape}\")  # Print the shape of the probe data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3xLl4nTowS_a"
      },
      "source": [
        "### Computing the PSD using Welch's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "JfEpgjIhwS_a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title('Probe PSD for channel 1')\n",
        "plt.plot(probe_LFP[0, 0:1000], 'royalblue')\n",
        "plt.xlabel('Time (ms)')\n",
        "plt.ylabel('Amplitude')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "probe_freqs, probe_psd = signal.welch(probe_LFP[0, :], fs=probe_fs, nperseg=1024)\n",
        "plt.plot(probe_freqs, probe_psd, color='royalblue')\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power')\n",
        "plt.xlim([0, 100])\n",
        "plt.show()\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2Nv4tV62zXq"
      },
      "outputs": [],
      "source": [
        "probe_freqs, probe_psd = signal.welch(probe_LFP, fs=probe_fs, nperseg=1024)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.title('Probe PSD for all channels')\n",
        "plt.plot(probe_freqs, probe_psd.T, color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power')\n",
        "plt.xlim([0, 100])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr5iZGkd2zXq"
      },
      "source": [
        "#### Normalizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Het9nzpc2zXr"
      },
      "outputs": [],
      "source": [
        "probe_freqs, probe_psd = signal.welch(probe_LFP, fs=probe_fs, nperseg=1024)\n",
        "\n",
        "plt.figure(figsize=(10, 16))\n",
        "\n",
        "plt.subplot(4, 1, 1)  # Original Probe PSD for all channels\n",
        "plt.plot(probe_freqs, probe_psd.T, color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.subplot(4, 1, 2)  # Standard Normalization\n",
        "plt.plot(probe_freqs, probe_psd.T / np.max(probe_psd, axis=1), color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Normalized power')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.subplot(4, 1, 3)  # dB Normalization\n",
        "plt.plot(probe_freqs, 10 * np.log10(probe_psd.T / np.max(probe_psd, axis=1)), color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power (dB)')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.subplot(4, 1, 4)  # Z-scoring\n",
        "plt.plot(probe_freqs, (probe_psd.T - np.mean(probe_psd, axis=1)) / np.std(probe_psd, axis=1), color='royalblue', alpha=0.5)\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Z-scored power')\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COY-sHz02zXr"
      },
      "source": [
        "### The PSD usually varies with time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnCKXjW52zXr"
      },
      "outputs": [],
      "source": [
        "# Power spectral density of an artificial signal\n",
        "\n",
        "fs = 1000.  # Sampling frequency\n",
        "dt = 1./fs  # Time step\n",
        "t = np.arange(dt,5.00001,dt)  # Time array\n",
        "\n",
        "LFP = np.sin(2*np.pi*8*t)  # Generate artificial signal\n",
        "LFP[:2500] = 0  # Set initial portion to 0\n",
        "LFP = LFP + 0.7*np.sin(2*np.pi*20*t)  # Add another sinusoid\n",
        "\n",
        "plt.figure(figsize=(12,8))  # Create a figure\n",
        "ax1 = plt.subplot2grid((6,1),(0,0),rowspan=2)  # Define subplot for time series\n",
        "ax1.plot(t,LFP, color='royalblue')  # Plot the artificial signal\n",
        "ax1.set_xlabel('Time [s]')  # Set x-axis label\n",
        "ax1.set_xlim([0,5])  # Set x-axis limits\n",
        "\n",
        "win = 0.5*fs  # Define window length\n",
        "overlap = 0.5*win  # Define overlap\n",
        "nfft = 5000  # Define number of FFT points\n",
        "\n",
        "F,Pxx = signal.welch(LFP,fs,nperseg=win,noverlap=overlap,nfft=nfft)  # Compute Welch's method\n",
        "\n",
        "ax2 = plt.subplot2grid((6,1),(3,0),rowspan=3)  # Define subplot for power spectral density\n",
        "ax2.plot(F,Pxx,'ko-')  # Plot the power spectral density\n",
        "ax2.set_xlabel('Frequency [Hz]')  # Set x-axis label\n",
        "ax2.set_ylabel('Power')  # Set y-axis label\n",
        "ax2.set_xlim([0,30])  # Set x-axis limits\n",
        "plt.show()  # Display the plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-CiXIjE2zXr"
      },
      "source": [
        "---\n",
        "# Section 3: Time-Frequency Analyses\n",
        "\n",
        "*Estimated timing to here from start of tutorial: 30 min*\n",
        "\n",
        "This section focuses on computing spectrograms, revealing the time-frequency profile of spectral power in LFP data. Spectrograms provide a dynamic view of neural activity, allowing us to uncover patterns that evolve over time.\n",
        "\n",
        "Procedure:\n",
        "\n",
        "**Spectrogram Calculation:**\n",
        "Utilize time-frequency analysis techniques to compute the spectrogram of LFP signals.\n",
        "\n",
        "**Visualization:**\n",
        "Create visualizations that represent the time-dependent changes in spectral power."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8Vn9XNg2zXr"
      },
      "outputs": [],
      "source": [
        "windowlen = int(2.*fs)      # Define window length in seconds\n",
        "stepsize  = int(0.1*windowlen) # Calculate percentage of overlapping\n",
        "Nwindows  = int((len(LFP)-windowlen)/stepsize+1)  # Calculate the number of windows\n",
        "\n",
        "T = np.empty(Nwindows)  # Initialize array to store time values\n",
        "TFD = np.empty((Nwindows,round(len(t)/2+1)))  # Initialize array to store time-frequency data\n",
        "for nwin in range(Nwindows):  # Iterate over each window\n",
        "    winsample = np.arange(windowlen) + (nwin-1)*stepsize  # Define the sample window\n",
        "    F,Pxx = signal.welch(LFP[winsample],fs=fs,nperseg=windowlen,nfft=nfft)  # Compute Welch's method\n",
        "    T[nwin] = t[int(winsample[int(windowlen/2)])]  # Store the time value\n",
        "    TFD[nwin,:] = Pxx  # Store the power spectral density\n",
        "\n",
        "plt.figure(figsize=(12,6))  # Create a figure for the spectrogram\n",
        "plt.pcolormesh(T,F,TFD.T)  # Plot the spectrogram\n",
        "plt.ylim([0,30])  # Set the y-axis limit\n",
        "plt.xlabel('Time [s]')  # Set the x-axis label\n",
        "plt.ylabel('Frequency [Hz]')  # Set the y-axis label\n",
        "plt.colorbar(label='Power')  # Add colorbar\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3bNWQ1X2zXr"
      },
      "source": [
        "### Visualizing the frequency power changes through time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_gYRpplp2zXr"
      },
      "outputs": [],
      "source": [
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "@widgets.interact(time=widgets.IntSlider(0, min=0, max=TFD.shape[0]-1, step=1))\n",
        "def update_plot(time):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.xlabel('Frequency [Hz]')\n",
        "    plt.ylabel('Power')\n",
        "    plt.plot(F,TFD[int(time),:])\n",
        "    plt.xlim([0,30])\n",
        "    plt.ylim([0,1])\n",
        "    plt.title('Time = '+str(T[time])+' s')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ8XDxKm2zXs"
      },
      "outputs": [],
      "source": [
        "# Using the spectrogram function\n",
        "\n",
        "# Define parameters for the spectrogram\n",
        "window_length = 1*fs  # length of the window in seconds\n",
        "overlap = 0.9*window_length  # overlap between consecutive windows\n",
        "nfft = 2**13  # number of data points used in each block for the FFT\n",
        "\n",
        "# Compute the spectrogram\n",
        "F, T, Sxx = signal.spectrogram(LFP, fs, nperseg=int(window_length), noverlap=overlap, nfft=nfft)\n",
        "\n",
        "# Visualize the spectrogram\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.pcolormesh(T, F, Sxx)\n",
        "plt.ylim([0,30])\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.colorbar(label='Power');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w82hnlJV2zXs"
      },
      "source": [
        "---\n",
        "# Section 4: Computing Phase Coherence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYDca40q2zXs"
      },
      "source": [
        "In this section, we dive into the computation of phase coherence, a crucial measure in neuroscience for assessing the synchronization between different Local Field Potential (LFP) signals. Phase coherence provides valuable insights into the coordination of neural activity across multiple regions, shedding light on the underlying functional connectivity.\n",
        "\n",
        "Let's explore the steps involved in computing phase coherence and gain a deeper understanding of its significance in the context of mesoscopic neural dynamics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JI1xS8j2zXs"
      },
      "outputs": [],
      "source": [
        "# Compute the coherence value for a single frequency\n",
        "\n",
        "# Define the two frequencies\n",
        "freq1 = 8\n",
        "freq2 = 30\n",
        "fs = 1000\n",
        "\n",
        "# Create the time vector\n",
        "t = np.arange(0, 10, 1/fs)\n",
        "\n",
        "phi   = -np.deg2rad(180) # Phase difference of 180 degrees\n",
        "rand_phi = np.random.uniform(0, 2*np.pi, len(t)) # Random phase differences\n",
        "\n",
        "# Create two signals\n",
        "signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t)\n",
        "signal2 = 2* np.sin(2 * np.pi * freq1 * t + phi) + 2 * np.sin(2*np.pi*freq2*t + rand_phi) # Added phase difference to the second frequency in signal2\n",
        "\n",
        "# Set parameters for the coherence function\n",
        "noverlap = 0.5*fs # Amount of overlap between windows\n",
        "nfft = 2**13 # Number of points to compute the FFT- the larger the better the frequency resolution\n",
        "nperseg = window_length # Number of points per segment\n",
        "\n",
        "# Compute the coherence between the two signals\n",
        "frequencies, coherence = signal.coherence(signal1, signal2, fs=fs,\n",
        "                                          nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
        "\n",
        "# Plot the signals\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(t, signal1)\n",
        "plt.plot(t, signal2)\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlim([0, 1])\n",
        "\n",
        "# Plot the coherence\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(frequencies, coherence)\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.ylabel('Coherence')\n",
        "plt.xlim([0, 100])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OCZBCNvI2zXs"
      },
      "outputs": [],
      "source": [
        "# @markdown Make sure you execute this cell to enable the widget!\n",
        "@widgets.interact(noverlap=widgets.FloatSlider(0.5,min=0, max=1, step=0.1),\n",
        "               nfft=widgets.IntSlider(1024, min=1024, max=2**15, step=1024),\n",
        "               nperseg=widgets.IntSlider(1*fs, min=4, max=fs, step=1))\n",
        "\n",
        "\n",
        "# Interactive function to compute and plot coherence\n",
        "def interactive_coherence(noverlap, nfft, nperseg):\n",
        "    # Compute the coherence between the two signals\n",
        "    frequencies, coherence = signal.coherence(signal1, signal2, fs=fs,\n",
        "                                              nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
        "\n",
        "    # Plot the signals\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(t, signal1)\n",
        "    plt.plot(t, signal2)\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.xlim([0, 1])\n",
        "\n",
        "    # Plot the coherence\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(frequencies, coherence)\n",
        "    plt.xlabel('Frequency [Hz]')\n",
        "    plt.ylabel('Coherence')\n",
        "    plt.xlim([0, 100])\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jog-3Yz-2zXs"
      },
      "source": [
        "#### Coherence also varies in time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjZ2bqNb2zXs"
      },
      "outputs": [],
      "source": [
        "# Compute the coherence value for a single frequency\n",
        "\n",
        "# Define the two frequencies\n",
        "freq1 = 8\n",
        "freq2 = 30\n",
        "fs = 1000\n",
        "\n",
        "# Create the time vector\n",
        "t = np.arange(0, 10, 1/fs)\n",
        "\n",
        "# Phase difference of 180 degrees for the first 2 seconds and the last 5 seconds\n",
        "phi = np.ones_like(t) * -np.deg2rad(180)\n",
        "phi[(t >= 2) & (t < 4)] = np.random.uniform(0, 2*np.pi, len(t[(t >= 2) & (t < 4)]))\n",
        "rand_phi = np.random.uniform(0, 2*np.pi, len(t)) # Random phase differences\n",
        "\n",
        "\n",
        "# Create two signals\n",
        "signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t)\n",
        "signal2 = 2* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t + phi) # Added phase difference to the second frequency in signal2\n",
        "\n",
        "# Set parameters for the coherence function\n",
        "noverlap = 0.5*fs # Amount of overlap between windows\n",
        "nfft = 2**13 # Number of points to compute the FFT- the larger the better the frequency resolution\n",
        "nperseg = window_length # Number of points per segment\n",
        "\n",
        "# Compute the coherence between the two signals\n",
        "frequencies, coherence = signal.coherence(signal1, signal2, fs=fs,\n",
        "                                          nperseg=nperseg, noverlap=noverlap, nfft=nfft)\n",
        "\n",
        "\n",
        "# Plot the signals\n",
        "plt.figure(figsize=(10, 9))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(t, signal1)\n",
        "plt.plot(t, signal2)\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlim([0, 5])\n",
        "\n",
        "\n",
        "# Plot the coherence\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(frequencies, coherence)\n",
        "plt.xlabel('Frequency [Hz]')\n",
        "plt.ylabel('Coherence')\n",
        "plt.xlim([0, 100])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHliXuc32zXs"
      },
      "source": [
        "#### Meet the coherogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnV55kkZ2zXs"
      },
      "outputs": [],
      "source": [
        "# Define the two frequencies\n",
        "freq1 = 8\n",
        "freq2 = 30\n",
        "fs = 1000\n",
        "\n",
        "# Create the time vector\n",
        "t = np.arange(0, 30, 1/fs)\n",
        "\n",
        "# Phase difference of 180 degrees for the first 2 seconds and the last 5 seconds\n",
        "phi = np.ones_like(t) * -np.deg2rad(180)\n",
        "phi[(t >= 2) & (t < 10)] = np.random.uniform(0, 2*np.pi, len(t[(t >= 2) & (t < 10)]))\n",
        "rand_phi = np.random.uniform(0, 2*np.pi, len(t)) # Random phase differences\n",
        "\n",
        "\n",
        "# Create two signals\n",
        "signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t)\n",
        "signal2 = 2* np.sin(2 * np.pi * freq1 * t + phi) + 2 * np.sin(2*np.pi*freq2*t + rand_phi)\n",
        "\n",
        "#signal1 = 5* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t)\n",
        "#signal2 = 2* np.sin(2 * np.pi * freq1 * t) + 2 * np.sin(2*np.pi*freq2*t + phi) # Added phase difference to the second frequency in signal2\n",
        "\n",
        "\n",
        "\n",
        "win    = 10*fs # window size\n",
        "step   = 0.1*win # step size\n",
        "Nwin   = int((len(signal1)-win)/step+1)\n",
        "nfft   = 2**13\n",
        "cohwin = 1*fs # window within Cxy computation\n",
        "\n",
        "Coherogram = []\n",
        "T = []\n",
        "for nwin in range(Nwin):\n",
        "    temp = np.arange(win)+nwin*int(step)\n",
        "    F, Cxy = signal.coherence(signal1[temp],signal2[temp],fs=fs,nperseg=cohwin,nfft=nfft)\n",
        "    Coherogram.append(Cxy.T)\n",
        "    T.append(np.mean(temp/fs))\n",
        "\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.pcolormesh(T,F,np.transpose(Coherogram))\n",
        "plt.ylim([0,100])\n",
        "plt.xlabel('Time [s]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.colorbar(label='Coherence');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNNN9nO2zXt"
      },
      "source": [
        "---\n",
        "# Section 5: Calculating the Modulation Index between different frequencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsBQ36-x2zXt"
      },
      "source": [
        "Welcome to Section 5, where we explore the computation of the Modulation Index. This advanced analysis allows us to assess the interaction between signals of different frequencies, providing a nuanced perspective on how neural oscillations may modulate each other.\n",
        "\n",
        "The Modulation Index serves as a valuable tool in unraveling the complexities of mesoscopic neural dynamics, offering insights into frequency-specific interactions and potential coordination between distinct neural circuits.\n",
        "\n",
        "Let's delve into the steps of computing the Modulation Index and discover its relevance in advancing our understanding of the intricate interplay within the brain's local field potential data.\n",
        "\n",
        "The file LFP_HG_HFO contains simultaneous recordings of 2 LFP channels positioned on two different hippocampal layers. These channels have been named lfpHG and lfgHFO.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBZkXTZz2zXt"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = loadmat('LFP_HG_HFO.mat')\n",
        "lfpHG = data['lfpHG'][0]\n",
        "lfpHFO = data['lfpHFO'][0]\n",
        "\n",
        "# Set the sampling rate and calculate the time vector\n",
        "srate = 1000\n",
        "dt = 1./srate\n",
        "t = dt*(np.arange(len(lfpHG)))\n",
        "\n",
        "# Define nyquist frequency\n",
        "nyq = 0.5*srate\n",
        "\n",
        "LFP = lfpHG  # Assign lfpHG to LFP for further processing\n",
        "\n",
        "b,a = signal.butter(3,[5./nyq,10./nyq],'bandpass')  # Design a bandpass filter for the phase signal\n",
        "filteredPhase = signal.filtfilt(b,a,LFP)  # Apply the bandpass filter to the LFP signal\n",
        "\n",
        "b,a = signal.butter(3,[60./nyq,100./nyq],'bandpass')  # Design a bandpass filter for the amplitude signal\n",
        "filteredAmp = signal.filtfilt(b,a,LFP)  # Apply the bandpass filter to the LFP signal\n",
        "\n",
        "phase = np.angle(signal.hilbert(filteredPhase))  # Calculate the phase of the filtered phase signal\n",
        "amp = abs(signal.hilbert(filteredAmp))  # Calculate the amplitude of the filtered amplitude signal\n",
        "\n",
        "# Associated indices for each phase bin\n",
        "I = (np.rad2deg(phase)>-180)*(np.rad2deg(phase)<-160)  # Define indices for a specific phase range\n",
        "\n",
        "plt.figure(figsize=(16,10))  # Create a new figure with a specific size\n",
        "plt.subplot(211)  # Create a subplot in a 2x1 grid for the first plot\n",
        "plt.plot(t,LFP,'k-')  # Plot the LFP signal\n",
        "plt.plot(t,filteredPhase-1,linewidth=2)  # Plot the filtered phase signal\n",
        "plt.plot(t,8*filteredAmp-1.9,linewidth=1)  # Plot the filtered amplitude signal\n",
        "plt.plot(t,8*amp-1.9,'C1',linewidth=2)  # Plot the amplitude signal\n",
        "plt.xlim(40,42)  # Set the x-axis limits\n",
        "plt.ylim(-3,1)  # Set the y-axis limits\n",
        "\n",
        "plt.subplot(212)  # Create a subplot in a 2x1 grid for the second plot\n",
        "plt.plot(t,phase,'C0.')  # Plot the phase signal\n",
        "plt.plot(t[I],phase[I],'r.')  # Highlight the phase within the specified range\n",
        "plt.xlim(40,42)  # Set the x-axis limits\n",
        "plt.xlabel('Time (s)',size=13)  # Set the x-axis label\n",
        "plt.yticks([-np.pi,-np.pi/2,0,np.pi/2,np.pi],['-$\\pi$','-$\\pi$/2',0,'$\\pi$/2','$\\pi$'])  # Set the y-axis ticks\n",
        "\n",
        "plt.subplot(211)  # Create a subplot in a 2x1 grid for the third plot\n",
        "plt.plot(t[I],8*amp[I]-1.9,'r.')  # Highlight the amplitude within the specified range\n",
        "plt.yticks([-0.5,0,0.5])  # Set the y-axis ticks\n",
        "plt.title('Mean Amplitude = '+str(np.mean(amp[I])),size=14)  # Set the title for the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnB3t8xy2zXt"
      },
      "outputs": [],
      "source": [
        "# Mean amplitude for each phase bin\n",
        "\n",
        "# Define the phase vector\n",
        "phasevector = np.arange(-180,161,20)\n",
        "\n",
        "# Initialize an empty array for mean amplitude\n",
        "MeanAmp = np.empty(len(phasevector))\n",
        "\n",
        "# Calculate the mean amplitude for each phase bin\n",
        "for count,phasebin in enumerate(phasevector):\n",
        "    I = (np.rad2deg(phase)>phasebin)*(np.rad2deg(phase)<phasebin+20)\n",
        "    MeanAmp[count] = np.mean(amp[I])\n",
        "\n",
        "# Create a bar plot to visualize the mean amplitude\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(np.arange(10,711,20),np.concatenate((np.array(MeanAmp),np.array(MeanAmp))),\n",
        "        20,color='r',edgecolor='k')\n",
        "plt.xticks(np.arange(0,721,90))\n",
        "plt.xlabel('Theta Phase (^o)',size=13)\n",
        "plt.ylabel('Mean $\\gamma$ Amplitude (mV)',size=13)\n",
        "plt.xlim(0,720)\n",
        "\n",
        "# Calculate the entropy-based modulation index\n",
        "p = MeanAmp/sum(MeanAmp)\n",
        "H = -sum(p[p>0]*np.log(p[p>0]))\n",
        "N = len(MeanAmp)\n",
        "MI = (np.log(N)-H)/np.log(N)\n",
        "plt.title('Modulation Index = '+str(MI),size=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFJMuvPw2zXt"
      },
      "outputs": [],
      "source": [
        "# Phase-Amplitude comodulogram\n",
        "LFP = lfpHG\n",
        "\n",
        "phase_freq_vector = np.arange(1.,20.,2.)\n",
        "fp_bandwidth = 4\n",
        "amp_freq_vector = np.arange(20.,201.,5.)\n",
        "fa_bandwidth = 10\n",
        "\n",
        "MeanAmp = np.empty(len(phasevector))  # Initialize an empty array for mean amplitude\n",
        "Comodulogram = np.empty((len(phase_freq_vector),len(amp_freq_vector)))  # Initialize an empty array for the comodulogram\n",
        "\n",
        "for count_phase,fp in enumerate(phase_freq_vector):  # Loop through the phase frequency vector\n",
        "    b,a = signal.butter(3,[fp/nyq,(fp+fp_bandwidth)/nyq],'bandpass')  # Apply a Butterworth filter to the phase signal\n",
        "    filteredPhase = signal.filtfilt(b,a,LFP)  # Filter the LFP signal\n",
        "    phase = np.angle(signal.hilbert(filteredPhase))  # Calculate the phase of the filtered signal\n",
        "\n",
        "    for count_amp,fa in enumerate(amp_freq_vector):  # Loop through the amplitude frequency vector\n",
        "        b,a = signal.butter(3,[fa/nyq,(fa+fa_bandwidth)/nyq],'bandpass')  # Apply a Butterworth filter to the amplitude signal\n",
        "        filteredAmp = signal.filtfilt(b,a,LFP)  # Filter the LFP signal\n",
        "        amp = abs(signal.hilbert(filteredAmp))  # Calculate the amplitude of the filtered signal\n",
        "\n",
        "        for count,phasebin in enumerate(phasevector):  # Loop through the phase vector\n",
        "            I = (np.rad2deg(phase)>phasebin)*(np.rad2deg(phase)<(phasebin+20))  # Define the index for the specified phase range\n",
        "            MeanAmp[count] = np.mean(amp[I])  # Calculate the mean amplitude within the specified phase range\n",
        "\n",
        "        p = MeanAmp/sum(MeanAmp)  # Calculate the probability distribution\n",
        "        MI = (np.log(len(p))+sum(p[p>0]*np.log(p[p>0])))/np.log(len(p))  # Calculate the modulation index\n",
        "        Comodulogram[count_phase,count_amp] = MI  # Store the modulation index in the comodulogram array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKNvf_Np2zXt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.contourf(phase_freq_vector+fp_bandwidth/2.,amp_freq_vector+fa_bandwidth/2.,Comodulogram.T,30)\n",
        "plt.xlabel('Phase Frequency (Hz)',size=13)\n",
        "plt.ylabel('Amplitude Frequency (Hz)',size=13)\n",
        "plt.colorbar(label=\"Modulation Index\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3KSapdYRwS_a"
      },
      "source": [
        "---\n",
        "# Summary\n",
        "\n",
        "\n",
        "Congratulations on completing this micro-course on local field potential (LFP) analysis with open-source tools! Throughout this notebook, we delved into the fundamental aspects of signal processing and oscillation analyses in neuroscience. Let's recap the key highlights:\n",
        "\n",
        "## Key Learnings:\n",
        "\n",
        "1. **Visualizing Raw Signals and Identifying Artifacts:**\n",
        "   - Explored techniques for visualizing raw LFP signals and detecting artifacts that could impact subsequent analyses.\n",
        "\n",
        "2. **Transforming Signals: Temporal to Frequency Domain:**\n",
        "   - Mastered the transformation of temporal LFP signals into the frequency domain, gaining insights into the spectral composition of neural activity.\n",
        "\n",
        "3. **Computing Time-Frequency Profiles (Spectrogram):**\n",
        "   - Learned to compute spectrograms, revealing the dynamic changes in spectral power over time and providing a comprehensive view of neural oscillations.\n",
        "\n",
        "4. **Calculating Phase Coherence Between Signals:**\n",
        "   - Explored the computation of phase coherence, a vital measure for understanding synchronization between different LFP signals.\n",
        "\n",
        "5. **Determining Modulation Index Between Signals of Different Frequencies:**\n",
        "   - Investigated advanced analyses by calculating modulation indices between signals of distinct frequencies, uncovering intricate interactions in neural circuits.\n",
        "\n",
        "\n",
        "## Next Steps:\n",
        "\n",
        "This micro-course serves as a foundation for further exploration into the vast field of neuroscientific signal analysis. Consider applying these principles to real-world datasets and extending your knowledge into more advanced topics such as connectivity analysis, feature extraction, and machine learning applications in neuroscience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "B7xai9zLwS_a"
      },
      "source": [
        "---\n",
        "# Supplementary Materials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RIEwJoa1wS_a"
      },
      "source": [
        "## Databases:\n",
        "\n",
        "Explore openly available neural electrophysiology data from various websites for your research:\n",
        "\n",
        "- [CRCNS](crcns.org)\n",
        "- [IBL's Brainwide Map](https://www.internationalbrainlab.com/data)\n",
        "- [Zenodo](https://zenodo.org)\n",
        "- [figshare](figshare.com)\n",
        "- [Dryad](https://datadryad.org/stash)\n",
        "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
        "\n",
        "## Resources from the Open-Source Community:\n",
        "\n",
        "Discover valuable resources from the open-source community related to neuroscience:\n",
        "\n",
        "- [List of Neuroscience Databases](en.wikipedia.org/wiki/List_of_neuroscience_databases)\n",
        "- [NeuralEnsemble](http://neuralensemble.org)\n",
        "- [Open Computational Neuroscience Resources](https://github.com/asoplata/open-computational-neuroscience-resources)\n",
        "\n",
        "## Learning Materials:\n",
        "\n",
        "Enhance your knowledge with these learning materials:\n",
        "\n",
        "- [Analyzing Neural Time Series Data: Theory and Practice (Mike Cohen's book)](https://direct.mit.edu/books/book/4013/Analyzing-Neural-Time-Series-DataTheory-and)\n",
        "- [Mike X Cohen YT videos on signal processing for neuroscience](https://www.youtube.com/@mikexcohen1/playlists)\n",
        "- [Signal Analysis 2020.2 (Prof. Tort's Signal Analysis course repo on GitHub)](https://github.com/tortlab/SignalAnalysis2020.2)\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}